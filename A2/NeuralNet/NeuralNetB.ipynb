{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "training_data_path = \"../data/devnagri_train.csv\"\n",
    "testing_data_path = \"../data/devnagri_test_public.csv\"\n",
    "output_path = \"../data/out.txt\"\n",
    "output_size = 46\n",
    "hidden_layers_sizes = [ 25]\n",
    "activation = 'sigmoid'\n",
    "input_size = -1\n",
    "batch_size = 32\n",
    "n0 = 0.01\n",
    "max_iterations = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return (x>0) * x\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-1 * x))\n",
    "\n",
    "def reluPrime(x):\n",
    "    return (x>0)+0\n",
    "\n",
    "def tanhPrime(x):\n",
    "    return 1 - np.power(x,2)\n",
    "\n",
    "def sigmoidPrime(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def exp_normalize(x):\n",
    "    b = np.amax(x,axis=1,keepdims = True)\n",
    "    y = np.exp(x - b)\n",
    "    return y / y.sum(axis=1,keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self,input_size,output_size,hidden_layers_sizes, activation):\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        \n",
    "        if(activation == 'relu'):\n",
    "            self.activation = relu\n",
    "            self.activationPrime = reluPrime\n",
    "        elif(activation == 'tanh'):\n",
    "            self.activation = tanh\n",
    "            self.activationPrime = tanhPrime\n",
    "        else:\n",
    "            self.activation = sigmoid\n",
    "            self.activationPrime = sigmoidPrime\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hiddent_layers_sizes = hidden_layers_sizes\n",
    "        \n",
    "        prev_layer_count = input_size\n",
    "        \n",
    "        for i in range(len(hidden_layers_sizes) + 1):\n",
    "            if i==len(hidden_layers_sizes):\n",
    "                self.weights.append(np.random.rand(prev_layer_count, output_size)/100)\n",
    "                self.biases.append(np.random.rand(1, output_size)/100)        \n",
    "            else:\n",
    "                hidden_layer_count = hidden_layers_sizes[i]\n",
    "                self.weights.append(np.random.rand(prev_layer_count, hidden_layer_count)/100)\n",
    "                self.biases.append(np.random.rand(1, hidden_layer_count)/100)\n",
    "                prev_layer_count = hidden_layer_count\n",
    "        \n",
    "    def train(self,inpX,inpY,batch_size,n0,max_iterations):\n",
    "        max_examples = inpX.shape[0]\n",
    "        max_possible_iterations = int(0.5 + max_examples / batch_size)\n",
    "        num_hidden_layers = len(self.weights) - 1\n",
    "        \n",
    "        for n in range(max_iterations):\n",
    "            # Forming Mini Batches\n",
    "            i_eff = n%max_possible_iterations\n",
    "            \n",
    "            outputs = []\n",
    "            \n",
    "            if i_eff != max_possible_iterations - 1:\n",
    "                X = inpX[i_eff*batch_size: (i_eff+1)*batch_size]\n",
    "                Y = inpY[i_eff*batch_size: (i_eff+1)*batch_size]\n",
    "            else:\n",
    "                X = inpX[i_eff*batch_size:]\n",
    "                Y = inpY[i_eff*batch_size:]\n",
    "            \n",
    "            # Updating Learning Rate\n",
    "            lr = n0 / np.sqrt(n+1) \n",
    "                \n",
    "            # Neural Network Forward Propagation\n",
    "            outputs.append(X)\n",
    "            prev_layer_output = X\n",
    "            for i in range(num_hidden_layers + 1):\n",
    "                weight = self.weights[i]\n",
    "                bias = self.biases[i]\n",
    "                if i == num_hidden_layers:\n",
    "                    prev_layer_output = exp_normalize(prev_layer_output.dot(weight) + bias)\n",
    "                else:\n",
    "                    prev_layer_output = self.activation(prev_layer_output.dot(weight) + bias)\n",
    "                outputs.append(prev_layer_output)\n",
    "            \n",
    "            # Backpropagation\n",
    "            dWs = []\n",
    "            dbs = []\n",
    "            \n",
    "            for i in range(num_hidden_layers + 1,0,-1):\n",
    "                if i == num_hidden_layers + 1:\n",
    "                    delta = outputs[i].copy()\n",
    "                    delta[range(Y.shape[0]),Y] -= 1\n",
    "                else:\n",
    "                    delta = delta.dot(self.weights[i].T) * self.activationPrime(outputs[i])\n",
    "                dW = (outputs[i-1].T).dot(delta)\n",
    "                dWs.append(dW)\n",
    "                dbs.append(np.sum(delta,axis=0,keepdims=True))\n",
    "                \n",
    "            if (n%100 == 0):\n",
    "                probabilities = outputs[-1]\n",
    "                loss = np.sum(-1*np.log(probabilities[range(Y.shape[0]),Y])) / Y.shape[0]\n",
    "                labels = np.argmax(outputs[-1],axis = 1)\n",
    "                accuracy = 100 * np.sum(labels == Y)/Y.shape[0]\n",
    "                print(\"Iteration \",n,\" ,Loss = \",loss,\" ,Accuracy = \",accuracy,\"%\")\n",
    "                \n",
    "            dWs.reverse()\n",
    "            dbs.reverse()\n",
    "\n",
    "            # Gradient Descent Parameter Update\n",
    "            for i in range(len(dWs)):\n",
    "                self.weights[i] += dWs[i].dot(-1 * lr)\n",
    "                self.biases[i] += dbs[i].dot(-1 * lr)\n",
    "\n",
    "    def predict(self,X):\n",
    "        return self.forward_run(X)\n",
    "        \n",
    "    def forward_run(self,X):\n",
    "        prev_layer_output = X\n",
    "        num_hidden_layers = len(self.weights) - 1\n",
    "        for i in range(num_hidden_layers + 1):\n",
    "            weight = self.weights[i]\n",
    "            bias = self.biases[i]\n",
    "            if i == num_hidden_layers:\n",
    "                probabilities = exp_normalize(prev_layer_output.dot(weight) + bias)\n",
    "                labels = np.argmax(probabilities,axis = 1)\n",
    "                return labels\n",
    "            else:\n",
    "                prev_layer_output = self.activation(prev_layer_output.dot(weight) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path,avg,std):\n",
    "    if avg is None:\n",
    "        input_data = np.loadtxt(open(path, \"rb\"), delimiter=\",\")\n",
    "        Y = input_data[:,0].copy()\n",
    "        X = input_data[:,1:].copy()\n",
    "        avg = np.average(X,axis=0)\n",
    "        X = X - avg\n",
    "        std = np.std(X,axis=0)\n",
    "        std[(std == 0)] = 1\n",
    "        X = X / std\n",
    "        return X,Y,avg,std\n",
    "    else:\n",
    "        input_data = np.loadtxt(open(path, \"rb\"), delimiter=\",\")\n",
    "        X = input_data[:,1:].copy()\n",
    "        X = (X - avg)/std\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inpX,Y,avg,std = load_data(training_data_path,None,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0  ,Loss =  3.8294714914595644  ,Accuracy =  3.125 %\n",
      "Iteration  100  ,Loss =  3.829067446237522  ,Accuracy =  0.0 %\n",
      "Iteration  200  ,Loss =  3.8109589705095104  ,Accuracy =  6.25 %\n",
      "Iteration  300  ,Loss =  3.84049332515187  ,Accuracy =  6.25 %\n",
      "Iteration  400  ,Loss =  3.8314430764763063  ,Accuracy =  0.0 %\n",
      "Iteration  500  ,Loss =  3.8115281315985956  ,Accuracy =  3.125 %\n",
      "Iteration  600  ,Loss =  3.8319203749229853  ,Accuracy =  0.0 %\n",
      "Iteration  700  ,Loss =  3.7939466368457944  ,Accuracy =  0.0 %\n",
      "Iteration  800  ,Loss =  3.7960121609716326  ,Accuracy =  3.125 %\n",
      "Iteration  900  ,Loss =  3.8092776249288693  ,Accuracy =  6.25 %\n",
      "Iteration  1000  ,Loss =  3.812653351231339  ,Accuracy =  0.0 %\n",
      "Iteration  1100  ,Loss =  3.8026999431167363  ,Accuracy =  0.0 %\n",
      "Iteration  1200  ,Loss =  3.824351363726045  ,Accuracy =  0.0 %\n",
      "Iteration  1300  ,Loss =  3.792066183257571  ,Accuracy =  0.0 %\n",
      "Iteration  1400  ,Loss =  3.7892575881569086  ,Accuracy =  0.0 %\n",
      "Iteration  1500  ,Loss =  3.7659180833476724  ,Accuracy =  0.0 %\n",
      "Iteration  1600  ,Loss =  3.7852522132508266  ,Accuracy =  0.0 %\n",
      "Iteration  1700  ,Loss =  3.760176178254996  ,Accuracy =  6.25 %\n",
      "Iteration  1800  ,Loss =  3.7852949444550954  ,Accuracy =  0.0 %\n",
      "Iteration  1900  ,Loss =  3.8024615147177583  ,Accuracy =  3.125 %\n",
      "Iteration  2000  ,Loss =  3.7403237112136756  ,Accuracy =  3.125 %\n",
      "Iteration  2100  ,Loss =  3.7766676321284276  ,Accuracy =  3.125 %\n",
      "Iteration  2200  ,Loss =  3.6986638998035324  ,Accuracy =  18.75 %\n",
      "Iteration  2300  ,Loss =  3.723318667285678  ,Accuracy =  9.375 %\n",
      "Iteration  2400  ,Loss =  3.7431576492562746  ,Accuracy =  3.125 %\n",
      "Iteration  2500  ,Loss =  3.756140369582482  ,Accuracy =  3.125 %\n",
      "Iteration  2600  ,Loss =  3.7458190786982124  ,Accuracy =  6.25 %\n",
      "Iteration  2700  ,Loss =  3.7498620337562603  ,Accuracy =  9.375 %\n",
      "Iteration  2800  ,Loss =  3.7255243895271235  ,Accuracy =  15.625 %\n",
      "Iteration  2900  ,Loss =  3.6764984189098335  ,Accuracy =  12.5 %\n",
      "Iteration  3000  ,Loss =  3.7270393821810335  ,Accuracy =  6.25 %\n",
      "Iteration  3100  ,Loss =  3.6657128169740347  ,Accuracy =  12.5 %\n",
      "Iteration  3200  ,Loss =  3.6683716977628262  ,Accuracy =  6.25 %\n",
      "Iteration  3300  ,Loss =  3.763841471170392  ,Accuracy =  3.125 %\n",
      "Iteration  3400  ,Loss =  3.623325262648428  ,Accuracy =  12.5 %\n",
      "Iteration  3500  ,Loss =  3.707804439019663  ,Accuracy =  3.125 %\n",
      "Iteration  3600  ,Loss =  3.657369741642329  ,Accuracy =  3.125 %\n",
      "Iteration  3700  ,Loss =  3.6535147535945116  ,Accuracy =  6.25 %\n",
      "Iteration  3800  ,Loss =  3.6713912785459253  ,Accuracy =  6.25 %\n",
      "Iteration  3900  ,Loss =  3.582822665430589  ,Accuracy =  12.5 %\n",
      "Iteration  4000  ,Loss =  3.593444722557405  ,Accuracy =  12.5 %\n",
      "Iteration  4100  ,Loss =  3.5909891530553946  ,Accuracy =  18.75 %\n",
      "Iteration  4200  ,Loss =  3.6076982435599607  ,Accuracy =  15.625 %\n",
      "Iteration  4300  ,Loss =  3.6571057710538657  ,Accuracy =  9.375 %\n",
      "Iteration  4400  ,Loss =  3.627812462531917  ,Accuracy =  12.5 %\n",
      "Iteration  4500  ,Loss =  3.6111845290621867  ,Accuracy =  12.5 %\n",
      "Iteration  4600  ,Loss =  3.633669913744005  ,Accuracy =  9.375 %\n",
      "Iteration  4700  ,Loss =  3.5574979446276145  ,Accuracy =  12.5 %\n",
      "Iteration  4800  ,Loss =  3.556790248222442  ,Accuracy =  15.625 %\n",
      "Iteration  4900  ,Loss =  3.527700839011702  ,Accuracy =  28.125 %\n",
      "Iteration  5000  ,Loss =  3.4648802827879477  ,Accuracy =  21.875 %\n",
      "Iteration  5100  ,Loss =  3.510450561356136  ,Accuracy =  28.125 %\n",
      "Iteration  5200  ,Loss =  3.5440244503479286  ,Accuracy =  12.5 %\n",
      "Iteration  5300  ,Loss =  3.6003078079324617  ,Accuracy =  6.25 %\n",
      "Iteration  5400  ,Loss =  3.4839685538400387  ,Accuracy =  18.75 %\n",
      "Iteration  5500  ,Loss =  3.4152958202922603  ,Accuracy =  21.875 %\n",
      "Iteration  5600  ,Loss =  3.429577989648983  ,Accuracy =  18.75 %\n",
      "Iteration  5700  ,Loss =  3.477224439040276  ,Accuracy =  25.0 %\n",
      "Iteration  5800  ,Loss =  3.4174509581749932  ,Accuracy =  21.875 %\n",
      "Iteration  5900  ,Loss =  3.4921620982767085  ,Accuracy =  12.5 %\n",
      "Iteration  6000  ,Loss =  3.4841852963644313  ,Accuracy =  12.5 %\n",
      "Iteration  6100  ,Loss =  3.5379528987664868  ,Accuracy =  9.375 %\n",
      "Iteration  6200  ,Loss =  3.4580986919712178  ,Accuracy =  15.625 %\n",
      "Iteration  6300  ,Loss =  3.5028448780338484  ,Accuracy =  12.5 %\n",
      "Iteration  6400  ,Loss =  3.4012932802771205  ,Accuracy =  21.875 %\n",
      "Iteration  6500  ,Loss =  3.5279656904274628  ,Accuracy =  9.375 %\n",
      "Iteration  6600  ,Loss =  3.3729298744974994  ,Accuracy =  15.625 %\n",
      "Iteration  6700  ,Loss =  3.414286420641985  ,Accuracy =  9.375 %\n",
      "Iteration  6800  ,Loss =  3.442731176784079  ,Accuracy =  12.5 %\n",
      "Iteration  6900  ,Loss =  3.368389949814479  ,Accuracy =  21.875 %\n",
      "Iteration  7000  ,Loss =  3.441081252373231  ,Accuracy =  15.625 %\n",
      "Iteration  7100  ,Loss =  3.4191791115072405  ,Accuracy =  21.875 %\n",
      "Iteration  7200  ,Loss =  3.4627531796122364  ,Accuracy =  9.375 %\n",
      "Iteration  7300  ,Loss =  3.356403487403046  ,Accuracy =  18.75 %\n",
      "Iteration  7400  ,Loss =  3.2633108389270973  ,Accuracy =  25.0 %\n",
      "Iteration  7500  ,Loss =  3.433525123733858  ,Accuracy =  12.5 %\n",
      "Iteration  7600  ,Loss =  3.3142717032100935  ,Accuracy =  34.375 %\n",
      "Iteration  7700  ,Loss =  3.3674238280222326  ,Accuracy =  18.75 %\n",
      "Iteration  7800  ,Loss =  3.252943893886286  ,Accuracy =  37.5 %\n",
      "Iteration  7900  ,Loss =  3.3139568166803315  ,Accuracy =  18.75 %\n",
      "Iteration  8000  ,Loss =  3.297957378546445  ,Accuracy =  25.0 %\n",
      "Iteration  8100  ,Loss =  3.205140031033765  ,Accuracy =  34.375 %\n",
      "Iteration  8200  ,Loss =  3.216757304738484  ,Accuracy =  37.5 %\n",
      "Iteration  8300  ,Loss =  3.326735340853187  ,Accuracy =  28.125 %\n",
      "Iteration  8400  ,Loss =  3.236483786930703  ,Accuracy =  37.5 %\n",
      "Iteration  8500  ,Loss =  3.2488535697437637  ,Accuracy =  31.25 %\n",
      "Iteration  8600  ,Loss =  3.294566274936865  ,Accuracy =  25.0 %\n",
      "Iteration  8700  ,Loss =  3.2464049268057806  ,Accuracy =  21.875 %\n",
      "Iteration  8800  ,Loss =  3.143675111934767  ,Accuracy =  37.5 %\n",
      "Iteration  8900  ,Loss =  3.148776358095554  ,Accuracy =  31.25 %\n",
      "Iteration  9000  ,Loss =  3.1152744529484226  ,Accuracy =  43.75 %\n",
      "Iteration  9100  ,Loss =  3.407292969953229  ,Accuracy =  9.375 %\n",
      "Iteration  9200  ,Loss =  3.297695022718842  ,Accuracy =  15.625 %\n",
      "Iteration  9300  ,Loss =  3.1273469529939715  ,Accuracy =  40.625 %\n",
      "Iteration  9400  ,Loss =  3.2716284397224973  ,Accuracy =  18.75 %\n",
      "Iteration  9500  ,Loss =  3.2601389595310306  ,Accuracy =  25.0 %\n",
      "Iteration  9600  ,Loss =  3.3936113972353716  ,Accuracy =  15.625 %\n",
      "Iteration  9700  ,Loss =  3.13402351458201  ,Accuracy =  28.125 %\n",
      "Iteration  9800  ,Loss =  3.293908503015187  ,Accuracy =  12.5 %\n",
      "Iteration  9900  ,Loss =  3.153796597314981  ,Accuracy =  28.125 %\n",
      "Iteration  10000  ,Loss =  3.104029683065253  ,Accuracy =  25.0 %\n",
      "Iteration  10100  ,Loss =  3.1213109237874113  ,Accuracy =  31.25 %\n",
      "Iteration  10200  ,Loss =  3.2309975713048056  ,Accuracy =  21.875 %\n",
      "Iteration  10300  ,Loss =  2.9883231281933154  ,Accuracy =  37.5 %\n",
      "Iteration  10400  ,Loss =  3.1791754878737035  ,Accuracy =  21.875 %\n",
      "Iteration  10500  ,Loss =  3.1076169599888344  ,Accuracy =  34.375 %\n",
      "Iteration  10600  ,Loss =  3.047655984683342  ,Accuracy =  40.625 %\n",
      "Iteration  10700  ,Loss =  3.2360075586751202  ,Accuracy =  25.0 %\n",
      "Iteration  10800  ,Loss =  3.036273360018696  ,Accuracy =  28.125 %\n",
      "Iteration  10900  ,Loss =  3.1479831629217343  ,Accuracy =  31.25 %\n",
      "Iteration  11000  ,Loss =  3.2200573000567037  ,Accuracy =  21.875 %\n",
      "Iteration  11100  ,Loss =  3.081056874867029  ,Accuracy =  40.625 %\n",
      "Iteration  11200  ,Loss =  3.0731174788600057  ,Accuracy =  31.25 %\n",
      "Iteration  11300  ,Loss =  3.170127431103043  ,Accuracy =  31.25 %\n",
      "Iteration  11400  ,Loss =  3.0886629362348668  ,Accuracy =  25.0 %\n",
      "Iteration  11500  ,Loss =  3.1471477936011727  ,Accuracy =  25.0 %\n",
      "Iteration  11600  ,Loss =  3.0513279997875156  ,Accuracy =  25.0 %\n",
      "Iteration  11700  ,Loss =  3.017780630172011  ,Accuracy =  34.375 %\n",
      "Iteration  11800  ,Loss =  2.99334766638393  ,Accuracy =  40.625 %\n",
      "Iteration  11900  ,Loss =  2.95396326861402  ,Accuracy =  31.25 %\n",
      "Iteration  12000  ,Loss =  3.0896869619402803  ,Accuracy =  31.25 %\n",
      "Iteration  12100  ,Loss =  2.908364483755813  ,Accuracy =  37.5 %\n",
      "Iteration  12200  ,Loss =  2.946902394940941  ,Accuracy =  34.375 %\n",
      "Iteration  12300  ,Loss =  2.975489722304688  ,Accuracy =  31.25 %\n",
      "Iteration  12400  ,Loss =  3.04852221112887  ,Accuracy =  37.5 %\n",
      "Iteration  12500  ,Loss =  3.045134459498282  ,Accuracy =  34.375 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  12600  ,Loss =  3.146636403159217  ,Accuracy =  28.125 %\n",
      "Iteration  12700  ,Loss =  3.037052057801586  ,Accuracy =  43.75 %\n",
      "Iteration  12800  ,Loss =  2.93543501570677  ,Accuracy =  34.375 %\n",
      "Iteration  12900  ,Loss =  2.924296007787217  ,Accuracy =  37.5 %\n",
      "Iteration  13000  ,Loss =  3.039575338018289  ,Accuracy =  34.375 %\n",
      "Iteration  13100  ,Loss =  2.9326143325718026  ,Accuracy =  37.5 %\n",
      "Iteration  13200  ,Loss =  2.8490071121097644  ,Accuracy =  46.875 %\n",
      "Iteration  13300  ,Loss =  2.921202440611854  ,Accuracy =  34.375 %\n",
      "Iteration  13400  ,Loss =  3.0460815681077076  ,Accuracy =  18.75 %\n",
      "Iteration  13500  ,Loss =  2.820456088104151  ,Accuracy =  31.25 %\n",
      "Iteration  13600  ,Loss =  3.0964507396970413  ,Accuracy =  21.875 %\n",
      "Iteration  13700  ,Loss =  2.9903568010043733  ,Accuracy =  21.875 %\n",
      "Iteration  13800  ,Loss =  2.9786620917561066  ,Accuracy =  37.5 %\n",
      "Iteration  13900  ,Loss =  2.959975487791561  ,Accuracy =  37.5 %\n",
      "Iteration  14000  ,Loss =  3.0099530320576795  ,Accuracy =  31.25 %\n",
      "Iteration  14100  ,Loss =  2.87399947819172  ,Accuracy =  53.125 %\n",
      "Iteration  14200  ,Loss =  2.952914412477271  ,Accuracy =  34.375 %\n",
      "Iteration  14300  ,Loss =  2.9607503230963377  ,Accuracy =  40.625 %\n",
      "Iteration  14400  ,Loss =  2.8481697071445877  ,Accuracy =  40.625 %\n",
      "Iteration  14500  ,Loss =  2.826987549611017  ,Accuracy =  37.5 %\n",
      "Iteration  14600  ,Loss =  2.8669839191674473  ,Accuracy =  31.25 %\n",
      "Iteration  14700  ,Loss =  2.795768147995423  ,Accuracy =  43.75 %\n",
      "Iteration  14800  ,Loss =  2.985416220785491  ,Accuracy =  43.75 %\n",
      "Iteration  14900  ,Loss =  2.7910023497427208  ,Accuracy =  46.875 %\n",
      "Iteration  15000  ,Loss =  2.956521922967016  ,Accuracy =  28.125 %\n",
      "Iteration  15100  ,Loss =  2.8961647083794295  ,Accuracy =  34.375 %\n",
      "Iteration  15200  ,Loss =  2.9001211117752463  ,Accuracy =  34.375 %\n",
      "Iteration  15300  ,Loss =  2.9974357675259955  ,Accuracy =  28.125 %\n",
      "Iteration  15400  ,Loss =  2.937175084033941  ,Accuracy =  31.25 %\n",
      "Iteration  15500  ,Loss =  2.7686316819005032  ,Accuracy =  43.75 %\n",
      "Iteration  15600  ,Loss =  2.933525219126235  ,Accuracy =  40.625 %\n",
      "Iteration  15700  ,Loss =  2.915994331952435  ,Accuracy =  25.0 %\n",
      "Iteration  15800  ,Loss =  3.0751827731529704  ,Accuracy =  34.375 %\n",
      "Iteration  15900  ,Loss =  3.0010238875016277  ,Accuracy =  31.25 %\n",
      "Iteration  16000  ,Loss =  2.871993631926237  ,Accuracy =  21.875 %\n",
      "Iteration  16100  ,Loss =  2.8504185697607882  ,Accuracy =  40.625 %\n",
      "Iteration  16200  ,Loss =  2.818458485470877  ,Accuracy =  40.625 %\n",
      "Iteration  16300  ,Loss =  3.024277084891438  ,Accuracy =  37.5 %\n",
      "Iteration  16400  ,Loss =  2.8838143689431144  ,Accuracy =  40.625 %\n",
      "Iteration  16500  ,Loss =  2.7717579462055246  ,Accuracy =  37.5 %\n",
      "Iteration  16600  ,Loss =  3.018904066777285  ,Accuracy =  34.375 %\n",
      "Iteration  16700  ,Loss =  2.906388327587521  ,Accuracy =  31.25 %\n",
      "Iteration  16800  ,Loss =  2.6011306783095547  ,Accuracy =  53.125 %\n",
      "Iteration  16900  ,Loss =  2.7371719294140204  ,Accuracy =  34.375 %\n",
      "Iteration  17000  ,Loss =  3.007137499262871  ,Accuracy =  34.375 %\n",
      "Iteration  17100  ,Loss =  2.906938762454243  ,Accuracy =  25.0 %\n",
      "Iteration  17200  ,Loss =  2.95280969562159  ,Accuracy =  31.25 %\n",
      "Iteration  17300  ,Loss =  2.826311560711578  ,Accuracy =  31.25 %\n",
      "Iteration  17400  ,Loss =  2.712442397601471  ,Accuracy =  53.125 %\n",
      "Iteration  17500  ,Loss =  2.801862565518455  ,Accuracy =  28.125 %\n",
      "Iteration  17600  ,Loss =  2.897884832626299  ,Accuracy =  31.25 %\n",
      "Iteration  17700  ,Loss =  2.623253120055982  ,Accuracy =  37.5 %\n",
      "Iteration  17800  ,Loss =  2.7468097070810193  ,Accuracy =  28.125 %\n",
      "Iteration  17900  ,Loss =  2.8435980668118748  ,Accuracy =  40.625 %\n",
      "Iteration  18000  ,Loss =  2.743540954022628  ,Accuracy =  34.375 %\n",
      "Iteration  18100  ,Loss =  2.758969504386531  ,Accuracy =  40.625 %\n",
      "Iteration  18200  ,Loss =  2.7808031065438055  ,Accuracy =  40.625 %\n",
      "Iteration  18300  ,Loss =  2.8534048015505773  ,Accuracy =  25.0 %\n",
      "Iteration  18400  ,Loss =  2.659584426156962  ,Accuracy =  46.875 %\n",
      "Iteration  18500  ,Loss =  2.8276242082540115  ,Accuracy =  40.625 %\n",
      "Iteration  18600  ,Loss =  2.8763641404319076  ,Accuracy =  31.25 %\n",
      "Iteration  18700  ,Loss =  2.8003581557718182  ,Accuracy =  31.25 %\n",
      "Iteration  18800  ,Loss =  2.8874073048623314  ,Accuracy =  21.875 %\n",
      "Iteration  18900  ,Loss =  2.6453255684742105  ,Accuracy =  43.75 %\n",
      "Iteration  19000  ,Loss =  2.7799820649706866  ,Accuracy =  34.375 %\n",
      "Iteration  19100  ,Loss =  2.661219069639954  ,Accuracy =  43.75 %\n",
      "Iteration  19200  ,Loss =  2.6991227793133357  ,Accuracy =  53.125 %\n",
      "Iteration  19300  ,Loss =  2.63753126785028  ,Accuracy =  43.75 %\n",
      "Iteration  19400  ,Loss =  2.675059697683661  ,Accuracy =  43.75 %\n",
      "Iteration  19500  ,Loss =  2.8476870400901655  ,Accuracy =  43.75 %\n",
      "Iteration  19600  ,Loss =  2.7653486567758883  ,Accuracy =  46.875 %\n",
      "Iteration  19700  ,Loss =  2.8471227325476716  ,Accuracy =  40.625 %\n",
      "Iteration  19800  ,Loss =  2.670863192594768  ,Accuracy =  40.625 %\n",
      "Iteration  19900  ,Loss =  2.708736089755779  ,Accuracy =  46.875 %\n",
      "Iteration  20000  ,Loss =  2.6980049759071134  ,Accuracy =  40.625 %\n",
      "Iteration  20100  ,Loss =  2.771588289527735  ,Accuracy =  37.5 %\n",
      "Iteration  20200  ,Loss =  2.675288285009083  ,Accuracy =  31.25 %\n",
      "Iteration  20300  ,Loss =  2.655679416061166  ,Accuracy =  25.0 %\n",
      "Iteration  20400  ,Loss =  2.720749127214605  ,Accuracy =  31.25 %\n",
      "Iteration  20500  ,Loss =  2.6897959643293383  ,Accuracy =  43.75 %\n",
      "Iteration  20600  ,Loss =  2.780546550467464  ,Accuracy =  34.375 %\n",
      "Iteration  20700  ,Loss =  2.6562677430926387  ,Accuracy =  46.875 %\n",
      "Iteration  20800  ,Loss =  2.838921447655997  ,Accuracy =  34.375 %\n",
      "Iteration  20900  ,Loss =  2.872174534188167  ,Accuracy =  34.375 %\n",
      "Iteration  21000  ,Loss =  2.882070745881845  ,Accuracy =  28.125 %\n",
      "Iteration  21100  ,Loss =  2.6414435853889495  ,Accuracy =  37.5 %\n",
      "Iteration  21200  ,Loss =  2.806340349297587  ,Accuracy =  43.75 %\n",
      "Iteration  21300  ,Loss =  2.554213688131045  ,Accuracy =  46.875 %\n",
      "Iteration  21400  ,Loss =  2.6804186386531796  ,Accuracy =  31.25 %\n",
      "Iteration  21500  ,Loss =  2.7184800665569124  ,Accuracy =  37.5 %\n",
      "Iteration  21600  ,Loss =  2.743142764371286  ,Accuracy =  37.5 %\n",
      "Iteration  21700  ,Loss =  2.6413662864545486  ,Accuracy =  40.625 %\n",
      "Iteration  21800  ,Loss =  2.5363343388426145  ,Accuracy =  46.875 %\n",
      "Iteration  21900  ,Loss =  2.8688467240770645  ,Accuracy =  31.25 %\n",
      "Iteration  22000  ,Loss =  2.7229724097753962  ,Accuracy =  59.375 %\n",
      "Iteration  22100  ,Loss =  2.8017865730248728  ,Accuracy =  37.5 %\n",
      "Iteration  22200  ,Loss =  2.690439040335473  ,Accuracy =  34.375 %\n",
      "Iteration  22300  ,Loss =  2.8192743781118255  ,Accuracy =  37.5 %\n",
      "Iteration  22400  ,Loss =  2.7287526502203274  ,Accuracy =  34.375 %\n",
      "Iteration  22500  ,Loss =  2.7415956002330484  ,Accuracy =  37.5 %\n",
      "Iteration  22600  ,Loss =  2.7722773316168596  ,Accuracy =  25.0 %\n",
      "Iteration  22700  ,Loss =  2.629496214645598  ,Accuracy =  34.375 %\n",
      "Iteration  22800  ,Loss =  2.4820417194815363  ,Accuracy =  53.125 %\n",
      "Iteration  22900  ,Loss =  2.8403803165758896  ,Accuracy =  25.0 %\n",
      "Iteration  23000  ,Loss =  2.5847064892291924  ,Accuracy =  46.875 %\n",
      "Iteration  23100  ,Loss =  2.6245844984538635  ,Accuracy =  46.875 %\n",
      "Iteration  23200  ,Loss =  2.6549066615581256  ,Accuracy =  31.25 %\n",
      "Iteration  23300  ,Loss =  2.558550449542265  ,Accuracy =  37.5 %\n",
      "Iteration  23400  ,Loss =  2.738199925843243  ,Accuracy =  34.375 %\n",
      "Iteration  23500  ,Loss =  3.105418547512428  ,Accuracy =  9.375 %\n",
      "Iteration  23600  ,Loss =  2.6019780294791466  ,Accuracy =  46.875 %\n",
      "Iteration  23700  ,Loss =  2.784160477042547  ,Accuracy =  40.625 %\n",
      "Iteration  23800  ,Loss =  2.720526830599616  ,Accuracy =  40.625 %\n",
      "Iteration  23900  ,Loss =  2.717224526529803  ,Accuracy =  40.625 %\n",
      "Iteration  24000  ,Loss =  2.65219003596149  ,Accuracy =  50.0 %\n",
      "Iteration  24100  ,Loss =  2.4981052965339705  ,Accuracy =  50.0 %\n",
      "Iteration  24200  ,Loss =  2.6170582796379613  ,Accuracy =  37.5 %\n",
      "Iteration  24300  ,Loss =  2.5794992299285635  ,Accuracy =  40.625 %\n",
      "Iteration  24400  ,Loss =  2.5654523690229967  ,Accuracy =  40.625 %\n",
      "Iteration  24500  ,Loss =  2.5898278769268503  ,Accuracy =  34.375 %\n",
      "Iteration  24600  ,Loss =  2.372849254105935  ,Accuracy =  50.0 %\n",
      "Iteration  24700  ,Loss =  2.6980479797108714  ,Accuracy =  40.625 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  24800  ,Loss =  2.6044620000282785  ,Accuracy =  43.75 %\n",
      "Iteration  24900  ,Loss =  2.655375661223488  ,Accuracy =  34.375 %\n",
      "Iteration  25000  ,Loss =  2.6326937343482766  ,Accuracy =  43.75 %\n",
      "Iteration  25100  ,Loss =  2.8300738522644844  ,Accuracy =  25.0 %\n",
      "Iteration  25200  ,Loss =  2.3921021754899012  ,Accuracy =  34.375 %\n",
      "Iteration  25300  ,Loss =  2.594832898000181  ,Accuracy =  43.75 %\n",
      "Iteration  25400  ,Loss =  2.6729376336445636  ,Accuracy =  34.375 %\n",
      "Iteration  25500  ,Loss =  2.7051896359019  ,Accuracy =  34.375 %\n",
      "Iteration  25600  ,Loss =  2.6327223979883048  ,Accuracy =  43.75 %\n",
      "Iteration  25700  ,Loss =  2.4602479804357618  ,Accuracy =  56.25 %\n",
      "Iteration  25800  ,Loss =  2.4323281721992585  ,Accuracy =  53.125 %\n",
      "Iteration  25900  ,Loss =  2.478511514518059  ,Accuracy =  56.25 %\n",
      "Iteration  26000  ,Loss =  2.7177576470950844  ,Accuracy =  34.375 %\n",
      "Iteration  26100  ,Loss =  2.468117326832413  ,Accuracy =  56.25 %\n",
      "Iteration  26200  ,Loss =  2.671469993217869  ,Accuracy =  34.375 %\n",
      "Iteration  26300  ,Loss =  2.6198355080566063  ,Accuracy =  40.625 %\n",
      "Iteration  26400  ,Loss =  2.5035321766704235  ,Accuracy =  43.75 %\n",
      "Iteration  26500  ,Loss =  2.44467008989918  ,Accuracy =  43.75 %\n",
      "Iteration  26600  ,Loss =  2.8095335531182517  ,Accuracy =  31.25 %\n",
      "Iteration  26700  ,Loss =  2.5273322698712084  ,Accuracy =  43.75 %\n",
      "Iteration  26800  ,Loss =  2.669110791080571  ,Accuracy =  21.875 %\n",
      "Iteration  26900  ,Loss =  2.443989263114446  ,Accuracy =  50.0 %\n",
      "Iteration  27000  ,Loss =  2.5284789938840024  ,Accuracy =  43.75 %\n",
      "Iteration  27100  ,Loss =  2.7852741784949893  ,Accuracy =  28.125 %\n",
      "Iteration  27200  ,Loss =  2.618384617842689  ,Accuracy =  43.75 %\n",
      "Iteration  27300  ,Loss =  2.5770767885383794  ,Accuracy =  46.875 %\n",
      "Iteration  27400  ,Loss =  2.42286800014136  ,Accuracy =  46.875 %\n",
      "Iteration  27500  ,Loss =  2.430683695298481  ,Accuracy =  50.0 %\n",
      "Iteration  27600  ,Loss =  2.7519784533061125  ,Accuracy =  40.625 %\n",
      "Iteration  27700  ,Loss =  2.620816748715475  ,Accuracy =  50.0 %\n",
      "Iteration  27800  ,Loss =  2.442803353989927  ,Accuracy =  50.0 %\n",
      "Iteration  27900  ,Loss =  2.5932217514644007  ,Accuracy =  53.125 %\n",
      "Iteration  28000  ,Loss =  2.6279164157712076  ,Accuracy =  28.125 %\n",
      "Iteration  28100  ,Loss =  2.5331309044198345  ,Accuracy =  43.75 %\n",
      "Iteration  28200  ,Loss =  2.6707923591119482  ,Accuracy =  43.75 %\n",
      "Iteration  28300  ,Loss =  2.4603479681984184  ,Accuracy =  43.75 %\n",
      "Iteration  28400  ,Loss =  2.4047756516161227  ,Accuracy =  37.5 %\n",
      "Iteration  28500  ,Loss =  2.569382123729169  ,Accuracy =  43.75 %\n",
      "Iteration  28600  ,Loss =  2.3136264942708853  ,Accuracy =  65.625 %\n",
      "Iteration  28700  ,Loss =  2.423564878817902  ,Accuracy =  50.0 %\n",
      "Iteration  28800  ,Loss =  2.6096144453398233  ,Accuracy =  43.75 %\n",
      "Iteration  28900  ,Loss =  2.258502356510742  ,Accuracy =  56.25 %\n",
      "Iteration  29000  ,Loss =  2.632283477627219  ,Accuracy =  40.625 %\n",
      "Iteration  29100  ,Loss =  2.5991898292705793  ,Accuracy =  40.625 %\n",
      "Iteration  29200  ,Loss =  2.5493598242710567  ,Accuracy =  40.625 %\n",
      "Iteration  29300  ,Loss =  2.5252555458028523  ,Accuracy =  37.5 %\n",
      "Iteration  29400  ,Loss =  2.535066806163789  ,Accuracy =  37.5 %\n",
      "Iteration  29500  ,Loss =  2.4388261822485076  ,Accuracy =  40.625 %\n",
      "Iteration  29600  ,Loss =  2.483143781839564  ,Accuracy =  46.875 %\n",
      "Iteration  29700  ,Loss =  2.502140571001678  ,Accuracy =  37.5 %\n",
      "Iteration  29800  ,Loss =  2.4877279016939466  ,Accuracy =  43.75 %\n",
      "Iteration  29900  ,Loss =  2.770401735853054  ,Accuracy =  21.875 %\n",
      "Iteration  30000  ,Loss =  2.5120692500262782  ,Accuracy =  43.75 %\n",
      "Iteration  30100  ,Loss =  2.3879686416033605  ,Accuracy =  53.125 %\n",
      "Iteration  30200  ,Loss =  2.6363169540383167  ,Accuracy =  40.625 %\n",
      "Iteration  30300  ,Loss =  2.212687660882512  ,Accuracy =  68.75 %\n",
      "Iteration  30400  ,Loss =  2.281635596782645  ,Accuracy =  59.375 %\n",
      "Iteration  30500  ,Loss =  2.7608521846887992  ,Accuracy =  34.375 %\n",
      "Iteration  30600  ,Loss =  2.3063690423550547  ,Accuracy =  56.25 %\n",
      "Iteration  30700  ,Loss =  2.4905091523676948  ,Accuracy =  43.75 %\n",
      "Iteration  30800  ,Loss =  2.5758696483775965  ,Accuracy =  43.75 %\n",
      "Iteration  30900  ,Loss =  2.5610721368838534  ,Accuracy =  40.625 %\n",
      "Iteration  31000  ,Loss =  2.367471657656507  ,Accuracy =  53.125 %\n",
      "Iteration  31100  ,Loss =  2.2813034409817146  ,Accuracy =  31.25 %\n",
      "Iteration  31200  ,Loss =  2.4510327202664612  ,Accuracy =  31.25 %\n",
      "Iteration  31300  ,Loss =  2.3888949468135117  ,Accuracy =  46.875 %\n",
      "Iteration  31400  ,Loss =  2.710114771314002  ,Accuracy =  40.625 %\n",
      "Iteration  31500  ,Loss =  2.3520602600036393  ,Accuracy =  46.875 %\n",
      "Iteration  31600  ,Loss =  2.4988294162202935  ,Accuracy =  43.75 %\n",
      "Iteration  31700  ,Loss =  2.47361471644627  ,Accuracy =  53.125 %\n",
      "Iteration  31800  ,Loss =  2.4941437636465755  ,Accuracy =  43.75 %\n",
      "Iteration  31900  ,Loss =  2.429555423828564  ,Accuracy =  43.75 %\n",
      "Iteration  32000  ,Loss =  2.4563057812494353  ,Accuracy =  46.875 %\n",
      "Iteration  32100  ,Loss =  2.6078942477065965  ,Accuracy =  59.375 %\n",
      "Iteration  32200  ,Loss =  2.4361979904729303  ,Accuracy =  37.5 %\n",
      "Iteration  32300  ,Loss =  2.4176476034717886  ,Accuracy =  31.25 %\n",
      "Iteration  32400  ,Loss =  2.322814373588047  ,Accuracy =  62.5 %\n",
      "Iteration  32500  ,Loss =  2.44424530332712  ,Accuracy =  53.125 %\n",
      "Iteration  32600  ,Loss =  2.4597466430323505  ,Accuracy =  56.25 %\n",
      "Iteration  32700  ,Loss =  2.342725990758076  ,Accuracy =  43.75 %\n",
      "Iteration  32800  ,Loss =  2.4011740832568464  ,Accuracy =  53.125 %\n",
      "Iteration  32900  ,Loss =  2.1883549745045263  ,Accuracy =  56.25 %\n",
      "Iteration  33000  ,Loss =  2.5065167652275333  ,Accuracy =  40.625 %\n",
      "Iteration  33100  ,Loss =  2.52992406537502  ,Accuracy =  53.125 %\n",
      "Iteration  33200  ,Loss =  2.4404124398383007  ,Accuracy =  53.125 %\n",
      "Iteration  33300  ,Loss =  2.363034283090873  ,Accuracy =  37.5 %\n",
      "Iteration  33400  ,Loss =  2.643035184343791  ,Accuracy =  40.625 %\n",
      "Iteration  33500  ,Loss =  2.410095178240046  ,Accuracy =  50.0 %\n",
      "Iteration  33600  ,Loss =  2.5912880254376685  ,Accuracy =  53.125 %\n",
      "Iteration  33700  ,Loss =  2.1799720705397663  ,Accuracy =  68.75 %\n",
      "Iteration  33800  ,Loss =  2.3858508379350116  ,Accuracy =  46.875 %\n",
      "Iteration  33900  ,Loss =  2.5855008898738854  ,Accuracy =  46.875 %\n",
      "Iteration  34000  ,Loss =  2.462243788023593  ,Accuracy =  43.75 %\n",
      "Iteration  34100  ,Loss =  2.280096176295353  ,Accuracy =  40.625 %\n",
      "Iteration  34200  ,Loss =  2.511779651466525  ,Accuracy =  50.0 %\n",
      "Iteration  34300  ,Loss =  2.344136361525358  ,Accuracy =  43.75 %\n",
      "Iteration  34400  ,Loss =  2.302246729806792  ,Accuracy =  59.375 %\n",
      "Iteration  34500  ,Loss =  2.357746080286965  ,Accuracy =  56.25 %\n",
      "Iteration  34600  ,Loss =  2.547436341238027  ,Accuracy =  53.125 %\n",
      "Iteration  34700  ,Loss =  2.2101128218984654  ,Accuracy =  53.125 %\n",
      "Iteration  34800  ,Loss =  2.4401550906925094  ,Accuracy =  46.875 %\n",
      "Iteration  34900  ,Loss =  2.4983295571948547  ,Accuracy =  40.625 %\n",
      "Iteration  35000  ,Loss =  2.2421697046326496  ,Accuracy =  59.375 %\n",
      "Iteration  35100  ,Loss =  2.4602832023916656  ,Accuracy =  40.625 %\n",
      "Iteration  35200  ,Loss =  2.5969226445761193  ,Accuracy =  31.25 %\n",
      "Iteration  35300  ,Loss =  2.7372018227499826  ,Accuracy =  28.125 %\n",
      "Iteration  35400  ,Loss =  2.325729447905423  ,Accuracy =  40.625 %\n",
      "Iteration  35500  ,Loss =  2.299021695426786  ,Accuracy =  40.625 %\n",
      "Iteration  35600  ,Loss =  2.2655065525462557  ,Accuracy =  59.375 %\n",
      "Iteration  35700  ,Loss =  2.5246610179683024  ,Accuracy =  40.625 %\n",
      "Iteration  35800  ,Loss =  2.335407650127042  ,Accuracy =  50.0 %\n",
      "Iteration  35900  ,Loss =  2.569234919794389  ,Accuracy =  34.375 %\n",
      "Iteration  36000  ,Loss =  2.519342560222447  ,Accuracy =  43.75 %\n",
      "Iteration  36100  ,Loss =  2.277107385805966  ,Accuracy =  43.75 %\n",
      "Iteration  36200  ,Loss =  2.240964979939471  ,Accuracy =  53.125 %\n",
      "Iteration  36300  ,Loss =  2.15922017522767  ,Accuracy =  56.25 %\n",
      "Iteration  36400  ,Loss =  2.3824835825131556  ,Accuracy =  43.75 %\n",
      "Iteration  36500  ,Loss =  2.421885152763088  ,Accuracy =  43.75 %\n",
      "Iteration  36600  ,Loss =  2.689180989134834  ,Accuracy =  25.0 %\n",
      "Iteration  36700  ,Loss =  2.307241320564077  ,Accuracy =  46.875 %\n",
      "Iteration  36800  ,Loss =  2.5080355777223104  ,Accuracy =  34.375 %\n",
      "Iteration  36900  ,Loss =  2.3938764265108214  ,Accuracy =  50.0 %\n",
      "Iteration  37000  ,Loss =  2.2486315048521366  ,Accuracy =  62.5 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  37100  ,Loss =  2.0808785051378473  ,Accuracy =  56.25 %\n",
      "Iteration  37200  ,Loss =  2.3884178150036663  ,Accuracy =  53.125 %\n",
      "Iteration  37300  ,Loss =  2.46159203780119  ,Accuracy =  50.0 %\n",
      "Iteration  37400  ,Loss =  2.2904745770215635  ,Accuracy =  56.25 %\n",
      "Iteration  37500  ,Loss =  2.3797697333771906  ,Accuracy =  40.625 %\n",
      "Iteration  37600  ,Loss =  2.393680353716056  ,Accuracy =  43.75 %\n",
      "Iteration  37700  ,Loss =  2.2838485336194596  ,Accuracy =  50.0 %\n",
      "Iteration  37800  ,Loss =  2.2342982572868983  ,Accuracy =  46.875 %\n",
      "Iteration  37900  ,Loss =  2.577964696831901  ,Accuracy =  40.625 %\n",
      "Iteration  38000  ,Loss =  2.436514161621097  ,Accuracy =  37.5 %\n",
      "Iteration  38100  ,Loss =  2.2931501420167333  ,Accuracy =  34.375 %\n",
      "Iteration  38200  ,Loss =  2.3140170385259955  ,Accuracy =  34.375 %\n",
      "Iteration  38300  ,Loss =  2.448199929838344  ,Accuracy =  31.25 %\n",
      "Iteration  38400  ,Loss =  2.2205644737157906  ,Accuracy =  50.0 %\n",
      "Iteration  38500  ,Loss =  2.3627850707691938  ,Accuracy =  50.0 %\n",
      "Iteration  38600  ,Loss =  2.3053563753252693  ,Accuracy =  46.875 %\n",
      "Iteration  38700  ,Loss =  2.1997367005711377  ,Accuracy =  56.25 %\n",
      "Iteration  38800  ,Loss =  2.3332337847981446  ,Accuracy =  46.875 %\n",
      "Iteration  38900  ,Loss =  2.4981716675434313  ,Accuracy =  40.625 %\n",
      "Iteration  39000  ,Loss =  2.254530917687064  ,Accuracy =  53.125 %\n",
      "Iteration  39100  ,Loss =  2.179156292316951  ,Accuracy =  46.875 %\n",
      "Iteration  39200  ,Loss =  2.1046589727694127  ,Accuracy =  46.875 %\n",
      "Iteration  39300  ,Loss =  2.7598633023110795  ,Accuracy =  21.875 %\n",
      "Iteration  39400  ,Loss =  2.2680483730565957  ,Accuracy =  50.0 %\n",
      "Iteration  39500  ,Loss =  2.3603179362047677  ,Accuracy =  50.0 %\n",
      "Iteration  39600  ,Loss =  2.259569081577488  ,Accuracy =  56.25 %\n",
      "Iteration  39700  ,Loss =  2.040645934902046  ,Accuracy =  56.25 %\n",
      "Iteration  39800  ,Loss =  2.1434035273231093  ,Accuracy =  53.125 %\n",
      "Iteration  39900  ,Loss =  2.1249133751063027  ,Accuracy =  46.875 %\n",
      "Iteration  40000  ,Loss =  2.191837300069792  ,Accuracy =  59.375 %\n",
      "Iteration  40100  ,Loss =  2.331870712401149  ,Accuracy =  56.25 %\n",
      "Iteration  40200  ,Loss =  2.2418330646025426  ,Accuracy =  56.25 %\n",
      "Iteration  40300  ,Loss =  2.4699274098571116  ,Accuracy =  40.625 %\n",
      "Iteration  40400  ,Loss =  2.150119702706062  ,Accuracy =  43.75 %\n",
      "Iteration  40500  ,Loss =  2.423735269188464  ,Accuracy =  43.75 %\n",
      "Iteration  40600  ,Loss =  2.3125485674453428  ,Accuracy =  40.625 %\n",
      "Iteration  40700  ,Loss =  2.329730639196171  ,Accuracy =  40.625 %\n",
      "Iteration  40800  ,Loss =  2.3305477526795664  ,Accuracy =  53.125 %\n",
      "Iteration  40900  ,Loss =  2.300466052749562  ,Accuracy =  43.75 %\n",
      "Iteration  41000  ,Loss =  2.033146509151604  ,Accuracy =  56.25 %\n",
      "Iteration  41100  ,Loss =  2.2553408922685354  ,Accuracy =  46.875 %\n",
      "Iteration  41200  ,Loss =  2.2349079864770576  ,Accuracy =  46.875 %\n",
      "Iteration  41300  ,Loss =  2.3058839560852866  ,Accuracy =  50.0 %\n",
      "Iteration  41400  ,Loss =  2.127553954471479  ,Accuracy =  56.25 %\n",
      "Iteration  41500  ,Loss =  1.9044379170157955  ,Accuracy =  65.625 %\n",
      "Iteration  41600  ,Loss =  2.235750584290603  ,Accuracy =  37.5 %\n",
      "Iteration  41700  ,Loss =  1.9517360679177833  ,Accuracy =  68.75 %\n",
      "Iteration  41800  ,Loss =  2.493630603767085  ,Accuracy =  40.625 %\n",
      "Iteration  41900  ,Loss =  2.440460391634647  ,Accuracy =  40.625 %\n",
      "Iteration  42000  ,Loss =  2.244044644211117  ,Accuracy =  56.25 %\n",
      "Iteration  42100  ,Loss =  2.202928588703638  ,Accuracy =  68.75 %\n",
      "Iteration  42200  ,Loss =  2.183509685777627  ,Accuracy =  43.75 %\n",
      "Iteration  42300  ,Loss =  2.2896775630841413  ,Accuracy =  43.75 %\n",
      "Iteration  42400  ,Loss =  2.1885912498746953  ,Accuracy =  56.25 %\n",
      "Iteration  42500  ,Loss =  2.2079420860186696  ,Accuracy =  56.25 %\n",
      "Iteration  42600  ,Loss =  2.4746762755385014  ,Accuracy =  34.375 %\n",
      "Iteration  42700  ,Loss =  2.4556394321664623  ,Accuracy =  43.75 %\n",
      "Iteration  42800  ,Loss =  2.1759720613143863  ,Accuracy =  62.5 %\n",
      "Iteration  42900  ,Loss =  2.419012470870972  ,Accuracy =  43.75 %\n",
      "Iteration  43000  ,Loss =  2.0742720571395954  ,Accuracy =  62.5 %\n",
      "Iteration  43100  ,Loss =  2.3447681316153695  ,Accuracy =  50.0 %\n",
      "Iteration  43200  ,Loss =  2.2546820168273642  ,Accuracy =  56.25 %\n",
      "Iteration  43300  ,Loss =  2.297700306293658  ,Accuracy =  56.25 %\n",
      "Iteration  43400  ,Loss =  2.3407180481369494  ,Accuracy =  40.625 %\n",
      "Iteration  43500  ,Loss =  2.37537084887087  ,Accuracy =  40.625 %\n",
      "Iteration  43600  ,Loss =  2.3703892496757266  ,Accuracy =  40.625 %\n",
      "Iteration  43700  ,Loss =  2.210664962717249  ,Accuracy =  50.0 %\n",
      "Iteration  43800  ,Loss =  2.545852856382051  ,Accuracy =  50.0 %\n",
      "Iteration  43900  ,Loss =  2.298516660928647  ,Accuracy =  43.75 %\n",
      "Iteration  44000  ,Loss =  2.418470761653187  ,Accuracy =  43.75 %\n",
      "Iteration  44100  ,Loss =  2.29514592209094  ,Accuracy =  50.0 %\n",
      "Iteration  44200  ,Loss =  2.0852129403210897  ,Accuracy =  59.375 %\n",
      "Iteration  44300  ,Loss =  1.905062488644962  ,Accuracy =  65.625 %\n",
      "Iteration  44400  ,Loss =  2.2897797161972835  ,Accuracy =  56.25 %\n",
      "Iteration  44500  ,Loss =  2.2443577839571853  ,Accuracy =  40.625 %\n",
      "Iteration  44600  ,Loss =  2.2690828754011685  ,Accuracy =  50.0 %\n",
      "Iteration  44700  ,Loss =  2.1690454870080615  ,Accuracy =  65.625 %\n",
      "Iteration  44800  ,Loss =  2.2518604743594253  ,Accuracy =  46.875 %\n",
      "Iteration  44900  ,Loss =  2.2632750188980224  ,Accuracy =  50.0 %\n",
      "Iteration  45000  ,Loss =  2.225004650034598  ,Accuracy =  56.25 %\n",
      "Iteration  45100  ,Loss =  2.3973594495770767  ,Accuracy =  34.375 %\n",
      "Iteration  45200  ,Loss =  2.092738065244319  ,Accuracy =  50.0 %\n",
      "Iteration  45300  ,Loss =  2.3206744020494487  ,Accuracy =  43.75 %\n",
      "Iteration  45400  ,Loss =  2.088299763577773  ,Accuracy =  50.0 %\n",
      "Iteration  45500  ,Loss =  2.2296495176285633  ,Accuracy =  53.125 %\n",
      "Iteration  45600  ,Loss =  2.0981243389075823  ,Accuracy =  50.0 %\n",
      "Iteration  45700  ,Loss =  2.2234467108713183  ,Accuracy =  43.75 %\n",
      "Iteration  45800  ,Loss =  2.3716991552105613  ,Accuracy =  34.375 %\n",
      "Iteration  45900  ,Loss =  2.2143803121738843  ,Accuracy =  46.875 %\n",
      "Iteration  46000  ,Loss =  2.117048921931268  ,Accuracy =  62.5 %\n",
      "Iteration  46100  ,Loss =  2.2078964768473908  ,Accuracy =  59.375 %\n",
      "Iteration  46200  ,Loss =  2.2554709568610054  ,Accuracy =  50.0 %\n",
      "Iteration  46300  ,Loss =  2.4617268195406368  ,Accuracy =  43.75 %\n",
      "Iteration  46400  ,Loss =  2.0159430490470918  ,Accuracy =  65.625 %\n",
      "Iteration  46500  ,Loss =  2.295301156795227  ,Accuracy =  46.875 %\n",
      "Iteration  46600  ,Loss =  2.075021549444288  ,Accuracy =  62.5 %\n",
      "Iteration  46700  ,Loss =  2.603523859313018  ,Accuracy =  34.375 %\n",
      "Iteration  46800  ,Loss =  2.1800095353635585  ,Accuracy =  50.0 %\n",
      "Iteration  46900  ,Loss =  2.098816551443829  ,Accuracy =  59.375 %\n",
      "Iteration  47000  ,Loss =  2.441463409951954  ,Accuracy =  46.875 %\n",
      "Iteration  47100  ,Loss =  2.2590056641782534  ,Accuracy =  43.75 %\n",
      "Iteration  47200  ,Loss =  2.129859619583409  ,Accuracy =  62.5 %\n",
      "Iteration  47300  ,Loss =  2.1868796917506543  ,Accuracy =  50.0 %\n",
      "Iteration  47400  ,Loss =  2.008993076063433  ,Accuracy =  43.75 %\n",
      "Iteration  47500  ,Loss =  2.180575713458039  ,Accuracy =  40.625 %\n",
      "Iteration  47600  ,Loss =  2.392559299183481  ,Accuracy =  43.75 %\n",
      "Iteration  47700  ,Loss =  2.1850768799119535  ,Accuracy =  56.25 %\n",
      "Iteration  47800  ,Loss =  2.428022939222908  ,Accuracy =  46.875 %\n",
      "Iteration  47900  ,Loss =  2.56428031602618  ,Accuracy =  40.625 %\n",
      "Iteration  48000  ,Loss =  2.1025426353439594  ,Accuracy =  50.0 %\n",
      "Iteration  48100  ,Loss =  2.1732802207971926  ,Accuracy =  34.375 %\n",
      "Iteration  48200  ,Loss =  2.2899482607983206  ,Accuracy =  28.125 %\n",
      "Iteration  48300  ,Loss =  1.921351667214889  ,Accuracy =  56.25 %\n",
      "Iteration  48400  ,Loss =  2.1681399421670298  ,Accuracy =  46.875 %\n",
      "Iteration  48500  ,Loss =  1.84288382838875  ,Accuracy =  56.25 %\n",
      "Iteration  48600  ,Loss =  2.195906681386661  ,Accuracy =  59.375 %\n",
      "Iteration  48700  ,Loss =  2.292923227439954  ,Accuracy =  53.125 %\n",
      "Iteration  48800  ,Loss =  2.3213821253732263  ,Accuracy =  46.875 %\n",
      "Iteration  48900  ,Loss =  2.3483221191646284  ,Accuracy =  46.875 %\n",
      "Iteration  49000  ,Loss =  2.367555725960208  ,Accuracy =  43.75 %\n",
      "Iteration  49100  ,Loss =  2.1803990168784964  ,Accuracy =  53.125 %\n",
      "Iteration  49200  ,Loss =  2.2711662264828076  ,Accuracy =  43.75 %\n",
      "Iteration  49300  ,Loss =  2.40305148128098  ,Accuracy =  40.625 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  49400  ,Loss =  2.5561541456516608  ,Accuracy =  37.5 %\n",
      "Iteration  49500  ,Loss =  2.2812247121828793  ,Accuracy =  46.875 %\n",
      "Iteration  49600  ,Loss =  2.275167537844287  ,Accuracy =  40.625 %\n",
      "Iteration  49700  ,Loss =  2.2038027249672822  ,Accuracy =  53.125 %\n",
      "Iteration  49800  ,Loss =  2.299129814208697  ,Accuracy =  43.75 %\n",
      "Iteration  49900  ,Loss =  2.1943296776101047  ,Accuracy =  53.125 %\n",
      "Iteration  50000  ,Loss =  2.238341890915075  ,Accuracy =  46.875 %\n",
      "Iteration  50100  ,Loss =  2.1555669354965703  ,Accuracy =  46.875 %\n",
      "Iteration  50200  ,Loss =  2.4860199825094753  ,Accuracy =  37.5 %\n",
      "Iteration  50300  ,Loss =  2.2360279239073746  ,Accuracy =  50.0 %\n",
      "Iteration  50400  ,Loss =  2.253161838606832  ,Accuracy =  46.875 %\n",
      "Iteration  50500  ,Loss =  2.405044884607335  ,Accuracy =  37.5 %\n",
      "Iteration  50600  ,Loss =  2.0498095603833417  ,Accuracy =  59.375 %\n",
      "Iteration  50700  ,Loss =  2.203200598419995  ,Accuracy =  56.25 %\n",
      "Iteration  50800  ,Loss =  2.060482104197549  ,Accuracy =  53.125 %\n",
      "Iteration  50900  ,Loss =  2.230633798211268  ,Accuracy =  50.0 %\n",
      "Iteration  51000  ,Loss =  2.3458476997896547  ,Accuracy =  46.875 %\n",
      "Iteration  51100  ,Loss =  2.4452523137146374  ,Accuracy =  40.625 %\n",
      "Iteration  51200  ,Loss =  2.161079740193676  ,Accuracy =  50.0 %\n",
      "Iteration  51300  ,Loss =  2.0031534684878696  ,Accuracy =  53.125 %\n",
      "Iteration  51400  ,Loss =  2.0384841650077385  ,Accuracy =  53.125 %\n",
      "Iteration  51500  ,Loss =  2.4318628043709287  ,Accuracy =  50.0 %\n",
      "Iteration  51600  ,Loss =  2.0619719121353706  ,Accuracy =  53.125 %\n",
      "Iteration  51700  ,Loss =  2.2035032752268267  ,Accuracy =  46.875 %\n",
      "Iteration  51800  ,Loss =  2.3262601413756046  ,Accuracy =  50.0 %\n",
      "Iteration  51900  ,Loss =  2.149949027100606  ,Accuracy =  50.0 %\n",
      "Iteration  52000  ,Loss =  2.141164992147057  ,Accuracy =  59.375 %\n",
      "Iteration  52100  ,Loss =  2.11290712770936  ,Accuracy =  62.5 %\n",
      "Iteration  52200  ,Loss =  2.21224338707909  ,Accuracy =  50.0 %\n",
      "Iteration  52300  ,Loss =  2.3423673927853086  ,Accuracy =  43.75 %\n",
      "Iteration  52400  ,Loss =  2.240154115065657  ,Accuracy =  43.75 %\n",
      "Iteration  52500  ,Loss =  2.175728770702886  ,Accuracy =  53.125 %\n",
      "Iteration  52600  ,Loss =  2.1046692973449606  ,Accuracy =  59.375 %\n",
      "Iteration  52700  ,Loss =  1.9616824381456266  ,Accuracy =  68.75 %\n",
      "Iteration  52800  ,Loss =  2.217625687639643  ,Accuracy =  43.75 %\n",
      "Iteration  52900  ,Loss =  2.3803725003230545  ,Accuracy =  34.375 %\n",
      "Iteration  53000  ,Loss =  2.158116478218678  ,Accuracy =  53.125 %\n",
      "Iteration  53100  ,Loss =  2.3345378594957067  ,Accuracy =  43.75 %\n",
      "Iteration  53200  ,Loss =  2.12141355289678  ,Accuracy =  56.25 %\n",
      "Iteration  53300  ,Loss =  2.541483632482448  ,Accuracy =  40.625 %\n",
      "Iteration  53400  ,Loss =  2.0144615586809516  ,Accuracy =  56.25 %\n",
      "Iteration  53500  ,Loss =  2.2937810521329656  ,Accuracy =  50.0 %\n",
      "Iteration  53600  ,Loss =  2.083641206959302  ,Accuracy =  53.125 %\n",
      "Iteration  53700  ,Loss =  2.008995076455371  ,Accuracy =  40.625 %\n",
      "Iteration  53800  ,Loss =  2.169598942874229  ,Accuracy =  56.25 %\n",
      "Iteration  53900  ,Loss =  2.2697047623683657  ,Accuracy =  46.875 %\n",
      "Iteration  54000  ,Loss =  2.1034824837760713  ,Accuracy =  56.25 %\n",
      "Iteration  54100  ,Loss =  2.3047640738006985  ,Accuracy =  37.5 %\n",
      "Iteration  54200  ,Loss =  2.093133076852455  ,Accuracy =  59.375 %\n",
      "Iteration  54300  ,Loss =  2.087327965003837  ,Accuracy =  53.125 %\n",
      "Iteration  54400  ,Loss =  2.1976088314822135  ,Accuracy =  50.0 %\n",
      "Iteration  54500  ,Loss =  2.1364765546544837  ,Accuracy =  59.375 %\n",
      "Iteration  54600  ,Loss =  2.093297106396353  ,Accuracy =  56.25 %\n",
      "Iteration  54700  ,Loss =  2.071798852176242  ,Accuracy =  53.125 %\n",
      "Iteration  54800  ,Loss =  2.139138362297226  ,Accuracy =  43.75 %\n",
      "Iteration  54900  ,Loss =  2.142856048420734  ,Accuracy =  56.25 %\n",
      "Iteration  55000  ,Loss =  2.3243970571291874  ,Accuracy =  43.75 %\n",
      "Iteration  55100  ,Loss =  2.2073881495949808  ,Accuracy =  50.0 %\n",
      "Iteration  55200  ,Loss =  2.1164212348519293  ,Accuracy =  56.25 %\n",
      "Iteration  55300  ,Loss =  2.0300750152369513  ,Accuracy =  65.625 %\n",
      "Iteration  55400  ,Loss =  1.9936921865965802  ,Accuracy =  50.0 %\n",
      "Iteration  55500  ,Loss =  2.33356011945669  ,Accuracy =  37.5 %\n",
      "Iteration  55600  ,Loss =  2.110717278002384  ,Accuracy =  53.125 %\n",
      "Iteration  55700  ,Loss =  2.415037291670041  ,Accuracy =  40.625 %\n",
      "Iteration  55800  ,Loss =  1.7997779224701707  ,Accuracy =  75.0 %\n",
      "Iteration  55900  ,Loss =  2.2928017580562985  ,Accuracy =  53.125 %\n",
      "Iteration  56000  ,Loss =  2.2074221953683733  ,Accuracy =  53.125 %\n",
      "Iteration  56100  ,Loss =  2.2309744459363072  ,Accuracy =  62.5 %\n",
      "Iteration  56200  ,Loss =  1.973149090523403  ,Accuracy =  65.625 %\n",
      "Iteration  56300  ,Loss =  1.9126407410844608  ,Accuracy =  62.5 %\n",
      "Iteration  56400  ,Loss =  2.0862923204939676  ,Accuracy =  59.375 %\n",
      "Iteration  56500  ,Loss =  2.1984258699051007  ,Accuracy =  46.875 %\n",
      "Iteration  56600  ,Loss =  2.329532231424213  ,Accuracy =  46.875 %\n",
      "Iteration  56700  ,Loss =  2.2741443672660457  ,Accuracy =  50.0 %\n",
      "Iteration  56800  ,Loss =  2.2311686221092826  ,Accuracy =  50.0 %\n",
      "Iteration  56900  ,Loss =  2.231905068430249  ,Accuracy =  46.875 %\n",
      "Iteration  57000  ,Loss =  2.021652115617576  ,Accuracy =  68.75 %\n",
      "Iteration  57100  ,Loss =  1.7858420538210864  ,Accuracy =  56.25 %\n",
      "Iteration  57200  ,Loss =  2.294229718375739  ,Accuracy =  34.375 %\n",
      "Iteration  57300  ,Loss =  2.3896046175944186  ,Accuracy =  40.625 %\n",
      "Iteration  57400  ,Loss =  2.3994782080794677  ,Accuracy =  31.25 %\n",
      "Iteration  57500  ,Loss =  1.9995956187898936  ,Accuracy =  53.125 %\n",
      "Iteration  57600  ,Loss =  2.415860226311045  ,Accuracy =  34.375 %\n",
      "Iteration  57700  ,Loss =  1.7807190001244195  ,Accuracy =  71.875 %\n",
      "Iteration  57800  ,Loss =  2.2383961946378244  ,Accuracy =  43.75 %\n",
      "Iteration  57900  ,Loss =  2.37557518108711  ,Accuracy =  50.0 %\n",
      "Iteration  58000  ,Loss =  2.2495759940877855  ,Accuracy =  50.0 %\n",
      "Iteration  58100  ,Loss =  1.8383049700215468  ,Accuracy =  62.5 %\n",
      "Iteration  58200  ,Loss =  2.1873821034838494  ,Accuracy =  53.125 %\n",
      "Iteration  58300  ,Loss =  1.8737592174666793  ,Accuracy =  50.0 %\n",
      "Iteration  58400  ,Loss =  2.3278654383007504  ,Accuracy =  43.75 %\n",
      "Iteration  58500  ,Loss =  1.8482693932444632  ,Accuracy =  68.75 %\n",
      "Iteration  58600  ,Loss =  2.0210563734820814  ,Accuracy =  62.5 %\n",
      "Iteration  58700  ,Loss =  2.0876958694716796  ,Accuracy =  43.75 %\n",
      "Iteration  58800  ,Loss =  2.254347397845006  ,Accuracy =  43.75 %\n",
      "Iteration  58900  ,Loss =  1.8736636632862078  ,Accuracy =  65.625 %\n",
      "Iteration  59000  ,Loss =  1.7948557866256416  ,Accuracy =  68.75 %\n",
      "Iteration  59100  ,Loss =  2.2831822894446216  ,Accuracy =  43.75 %\n",
      "Iteration  59200  ,Loss =  2.037870503644865  ,Accuracy =  46.875 %\n",
      "Iteration  59300  ,Loss =  2.0330170477722964  ,Accuracy =  62.5 %\n",
      "Iteration  59400  ,Loss =  2.1251660832373744  ,Accuracy =  62.5 %\n",
      "Iteration  59500  ,Loss =  2.0085641642941394  ,Accuracy =  56.25 %\n",
      "Iteration  59600  ,Loss =  1.8382610933374373  ,Accuracy =  59.375 %\n",
      "Iteration  59700  ,Loss =  2.0167960653534105  ,Accuracy =  50.0 %\n",
      "Iteration  59800  ,Loss =  1.9828309532293593  ,Accuracy =  53.125 %\n",
      "Iteration  59900  ,Loss =  2.207870944576525  ,Accuracy =  50.0 %\n",
      "Iteration  60000  ,Loss =  1.7674570870771302  ,Accuracy =  68.75 %\n",
      "Iteration  60100  ,Loss =  2.122233270729609  ,Accuracy =  59.375 %\n",
      "Iteration  60200  ,Loss =  1.9263790441625956  ,Accuracy =  68.75 %\n",
      "Iteration  60300  ,Loss =  2.178526994989678  ,Accuracy =  65.625 %\n",
      "Iteration  60400  ,Loss =  2.1775634454610935  ,Accuracy =  59.375 %\n",
      "Iteration  60500  ,Loss =  1.963825440288139  ,Accuracy =  62.5 %\n",
      "Iteration  60600  ,Loss =  1.855774380844987  ,Accuracy =  65.625 %\n",
      "Iteration  60700  ,Loss =  2.1810277540890346  ,Accuracy =  59.375 %\n",
      "Iteration  60800  ,Loss =  2.0950482942801223  ,Accuracy =  59.375 %\n",
      "Iteration  60900  ,Loss =  2.096761226080389  ,Accuracy =  53.125 %\n",
      "Iteration  61000  ,Loss =  2.1156046689149433  ,Accuracy =  50.0 %\n",
      "Iteration  61100  ,Loss =  2.141308765966848  ,Accuracy =  46.875 %\n",
      "Iteration  61200  ,Loss =  1.9105792575695943  ,Accuracy =  62.5 %\n",
      "Iteration  61300  ,Loss =  2.2795117388965283  ,Accuracy =  46.875 %\n",
      "Iteration  61400  ,Loss =  1.847406124899388  ,Accuracy =  68.75 %\n",
      "Iteration  61500  ,Loss =  1.8604948068711233  ,Accuracy =  62.5 %\n",
      "Iteration  61600  ,Loss =  2.168993451388376  ,Accuracy =  53.125 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  61700  ,Loss =  2.1590790155316966  ,Accuracy =  43.75 %\n",
      "Iteration  61800  ,Loss =  1.8439661954546704  ,Accuracy =  65.625 %\n",
      "Iteration  61900  ,Loss =  1.946528019789154  ,Accuracy =  62.5 %\n",
      "Iteration  62000  ,Loss =  2.3802781194508635  ,Accuracy =  46.875 %\n",
      "Iteration  62100  ,Loss =  2.2225584021657827  ,Accuracy =  46.875 %\n",
      "Iteration  62200  ,Loss =  1.9795628107599514  ,Accuracy =  53.125 %\n",
      "Iteration  62300  ,Loss =  2.1225083262668454  ,Accuracy =  50.0 %\n",
      "Iteration  62400  ,Loss =  2.026966258692748  ,Accuracy =  53.125 %\n",
      "Iteration  62500  ,Loss =  2.147007709657678  ,Accuracy =  46.875 %\n",
      "Iteration  62600  ,Loss =  2.129989848091879  ,Accuracy =  65.625 %\n",
      "Iteration  62700  ,Loss =  1.8217393140127882  ,Accuracy =  59.375 %\n",
      "Iteration  62800  ,Loss =  1.936801384346978  ,Accuracy =  46.875 %\n",
      "Iteration  62900  ,Loss =  2.2152128487254825  ,Accuracy =  43.75 %\n",
      "Iteration  63000  ,Loss =  2.275069710938336  ,Accuracy =  37.5 %\n",
      "Iteration  63100  ,Loss =  1.9023047608197974  ,Accuracy =  62.5 %\n",
      "Iteration  63200  ,Loss =  1.839091271499107  ,Accuracy =  56.25 %\n",
      "Iteration  63300  ,Loss =  1.9553601120305055  ,Accuracy =  59.375 %\n",
      "Iteration  63400  ,Loss =  2.036752299458599  ,Accuracy =  53.125 %\n",
      "Iteration  63500  ,Loss =  2.0707326946704514  ,Accuracy =  37.5 %\n",
      "Iteration  63600  ,Loss =  1.9579034573726335  ,Accuracy =  59.375 %\n",
      "Iteration  63700  ,Loss =  1.9892764151156106  ,Accuracy =  56.25 %\n",
      "Iteration  63800  ,Loss =  1.9845442141309593  ,Accuracy =  56.25 %\n",
      "Iteration  63900  ,Loss =  2.015356253930954  ,Accuracy =  59.375 %\n",
      "Iteration  64000  ,Loss =  1.7844694527326403  ,Accuracy =  65.625 %\n",
      "Iteration  64100  ,Loss =  1.8669826057927397  ,Accuracy =  62.5 %\n",
      "Iteration  64200  ,Loss =  2.036585013359415  ,Accuracy =  43.75 %\n",
      "Iteration  64300  ,Loss =  1.7554955501802514  ,Accuracy =  62.5 %\n",
      "Iteration  64400  ,Loss =  2.3387468713035755  ,Accuracy =  43.75 %\n",
      "Iteration  64500  ,Loss =  1.78003996946016  ,Accuracy =  56.25 %\n",
      "Iteration  64600  ,Loss =  2.1169498878627113  ,Accuracy =  56.25 %\n",
      "Iteration  64700  ,Loss =  1.9401569695406873  ,Accuracy =  59.375 %\n",
      "Iteration  64800  ,Loss =  1.9427971897410452  ,Accuracy =  59.375 %\n",
      "Iteration  64900  ,Loss =  2.1908550592439555  ,Accuracy =  53.125 %\n",
      "Iteration  65000  ,Loss =  2.115107364153783  ,Accuracy =  53.125 %\n",
      "Iteration  65100  ,Loss =  1.7161839048807117  ,Accuracy =  65.625 %\n",
      "Iteration  65200  ,Loss =  1.7534956094635175  ,Accuracy =  62.5 %\n",
      "Iteration  65300  ,Loss =  2.190330433972198  ,Accuracy =  65.625 %\n",
      "Iteration  65400  ,Loss =  2.0830701962838374  ,Accuracy =  46.875 %\n",
      "Iteration  65500  ,Loss =  2.1900257404651944  ,Accuracy =  46.875 %\n",
      "Iteration  65600  ,Loss =  2.0519132673966083  ,Accuracy =  46.875 %\n",
      "Iteration  65700  ,Loss =  2.1404233775798125  ,Accuracy =  56.25 %\n",
      "Iteration  65800  ,Loss =  1.9126471024946046  ,Accuracy =  53.125 %\n",
      "Iteration  65900  ,Loss =  2.0753963998730587  ,Accuracy =  53.125 %\n",
      "Iteration  66000  ,Loss =  1.811308851383105  ,Accuracy =  71.875 %\n",
      "Iteration  66100  ,Loss =  2.0059761339609987  ,Accuracy =  59.375 %\n",
      "Iteration  66200  ,Loss =  1.82065917266566  ,Accuracy =  59.375 %\n",
      "Iteration  66300  ,Loss =  1.835434497324134  ,Accuracy =  56.25 %\n",
      "Iteration  66400  ,Loss =  2.2859935635982755  ,Accuracy =  53.125 %\n",
      "Iteration  66500  ,Loss =  2.0244344855984826  ,Accuracy =  56.25 %\n",
      "Iteration  66600  ,Loss =  1.8495059361688464  ,Accuracy =  59.375 %\n",
      "Iteration  66700  ,Loss =  1.778745995958121  ,Accuracy =  71.875 %\n",
      "Iteration  66800  ,Loss =  2.0807526788379738  ,Accuracy =  46.875 %\n",
      "Iteration  66900  ,Loss =  1.8715691141417978  ,Accuracy =  68.75 %\n",
      "Iteration  67000  ,Loss =  2.0865060512420857  ,Accuracy =  53.125 %\n",
      "Iteration  67100  ,Loss =  2.1948229471379865  ,Accuracy =  43.75 %\n",
      "Iteration  67200  ,Loss =  2.1580691609721723  ,Accuracy =  43.75 %\n",
      "Iteration  67300  ,Loss =  2.247194827756993  ,Accuracy =  40.625 %\n",
      "Iteration  67400  ,Loss =  2.226451230526056  ,Accuracy =  50.0 %\n",
      "Iteration  67500  ,Loss =  1.8666702036328406  ,Accuracy =  62.5 %\n",
      "Iteration  67600  ,Loss =  2.195669273702478  ,Accuracy =  50.0 %\n",
      "Iteration  67700  ,Loss =  1.8575917233781307  ,Accuracy =  62.5 %\n",
      "Iteration  67800  ,Loss =  2.0650290405859675  ,Accuracy =  56.25 %\n",
      "Iteration  67900  ,Loss =  1.8728679050469799  ,Accuracy =  71.875 %\n",
      "Iteration  68000  ,Loss =  1.9420339805248203  ,Accuracy =  62.5 %\n",
      "Iteration  68100  ,Loss =  2.122579244419378  ,Accuracy =  56.25 %\n",
      "Iteration  68200  ,Loss =  2.170238907634284  ,Accuracy =  46.875 %\n",
      "Iteration  68300  ,Loss =  2.3286351606059332  ,Accuracy =  43.75 %\n",
      "Iteration  68400  ,Loss =  2.1790019828556813  ,Accuracy =  53.125 %\n",
      "Iteration  68500  ,Loss =  1.8048720449306037  ,Accuracy =  68.75 %\n",
      "Iteration  68600  ,Loss =  2.257151070980938  ,Accuracy =  40.625 %\n",
      "Iteration  68700  ,Loss =  2.020275235279715  ,Accuracy =  56.25 %\n",
      "Iteration  68800  ,Loss =  2.198864145021498  ,Accuracy =  50.0 %\n",
      "Iteration  68900  ,Loss =  1.9509864460984  ,Accuracy =  56.25 %\n",
      "Iteration  69000  ,Loss =  2.2004455498231614  ,Accuracy =  46.875 %\n",
      "Iteration  69100  ,Loss =  2.0527759608005436  ,Accuracy =  56.25 %\n",
      "Iteration  69200  ,Loss =  1.8063963625834338  ,Accuracy =  62.5 %\n",
      "Iteration  69300  ,Loss =  1.8831443014482077  ,Accuracy =  62.5 %\n",
      "Iteration  69400  ,Loss =  2.141651770137506  ,Accuracy =  43.75 %\n",
      "Iteration  69500  ,Loss =  1.9024653935634306  ,Accuracy =  56.25 %\n",
      "Iteration  69600  ,Loss =  2.0030719781846753  ,Accuracy =  59.375 %\n",
      "Iteration  69700  ,Loss =  1.9631226548406557  ,Accuracy =  59.375 %\n",
      "Iteration  69800  ,Loss =  2.0092768142147657  ,Accuracy =  43.75 %\n",
      "Iteration  69900  ,Loss =  1.8877050820636907  ,Accuracy =  65.625 %\n",
      "Iteration  70000  ,Loss =  1.8556015412676812  ,Accuracy =  53.125 %\n",
      "Iteration  70100  ,Loss =  1.8321982865097444  ,Accuracy =  56.25 %\n",
      "Iteration  70200  ,Loss =  2.565348093578946  ,Accuracy =  40.625 %\n",
      "Iteration  70300  ,Loss =  1.9749683377515967  ,Accuracy =  53.125 %\n",
      "Iteration  70400  ,Loss =  1.8448352866638125  ,Accuracy =  71.875 %\n",
      "Iteration  70500  ,Loss =  1.9906227091136333  ,Accuracy =  46.875 %\n",
      "Iteration  70600  ,Loss =  2.018095398581404  ,Accuracy =  59.375 %\n",
      "Iteration  70700  ,Loss =  2.46463518644206  ,Accuracy =  34.375 %\n",
      "Iteration  70800  ,Loss =  1.784874519305884  ,Accuracy =  65.625 %\n",
      "Iteration  70900  ,Loss =  2.34187330193617  ,Accuracy =  34.375 %\n",
      "Iteration  71000  ,Loss =  1.992253684979009  ,Accuracy =  59.375 %\n",
      "Iteration  71100  ,Loss =  1.8438316713790703  ,Accuracy =  62.5 %\n",
      "Iteration  71200  ,Loss =  1.9442468572576752  ,Accuracy =  71.875 %\n",
      "Iteration  71300  ,Loss =  2.141631455626094  ,Accuracy =  59.375 %\n",
      "Iteration  71400  ,Loss =  1.6633093556162395  ,Accuracy =  56.25 %\n",
      "Iteration  71500  ,Loss =  2.203377852084563  ,Accuracy =  50.0 %\n",
      "Iteration  71600  ,Loss =  2.0559484052350996  ,Accuracy =  50.0 %\n",
      "Iteration  71700  ,Loss =  1.8458317695122097  ,Accuracy =  56.25 %\n",
      "Iteration  71800  ,Loss =  2.2786572891523433  ,Accuracy =  43.75 %\n",
      "Iteration  71900  ,Loss =  1.6689743998276603  ,Accuracy =  68.75 %\n",
      "Iteration  72000  ,Loss =  2.0336786255071875  ,Accuracy =  43.75 %\n",
      "Iteration  72100  ,Loss =  2.2070198807275547  ,Accuracy =  50.0 %\n",
      "Iteration  72200  ,Loss =  1.8729266840283074  ,Accuracy =  65.625 %\n",
      "Iteration  72300  ,Loss =  1.9603966260173948  ,Accuracy =  56.25 %\n",
      "Iteration  72400  ,Loss =  2.0054562520488854  ,Accuracy =  59.375 %\n",
      "Iteration  72500  ,Loss =  1.9799962963941107  ,Accuracy =  50.0 %\n",
      "Iteration  72600  ,Loss =  2.3136157585201973  ,Accuracy =  34.375 %\n",
      "Iteration  72700  ,Loss =  1.9562125344528019  ,Accuracy =  50.0 %\n",
      "Iteration  72800  ,Loss =  1.906818917628459  ,Accuracy =  62.5 %\n",
      "Iteration  72900  ,Loss =  1.9899306041821663  ,Accuracy =  56.25 %\n",
      "Iteration  73000  ,Loss =  1.7929122536330997  ,Accuracy =  59.375 %\n",
      "Iteration  73100  ,Loss =  2.108001095685192  ,Accuracy =  65.625 %\n",
      "Iteration  73200  ,Loss =  1.808085840891019  ,Accuracy =  62.5 %\n",
      "Iteration  73300  ,Loss =  1.9254738600541295  ,Accuracy =  65.625 %\n",
      "Iteration  73400  ,Loss =  1.9228711721421385  ,Accuracy =  53.125 %\n",
      "Iteration  73500  ,Loss =  2.0445882727555102  ,Accuracy =  46.875 %\n",
      "Iteration  73600  ,Loss =  2.0534736513073  ,Accuracy =  56.25 %\n",
      "Iteration  73700  ,Loss =  2.0679700693637613  ,Accuracy =  46.875 %\n",
      "Iteration  73800  ,Loss =  1.9872124925535568  ,Accuracy =  59.375 %\n",
      "Iteration  73900  ,Loss =  1.9364787472127158  ,Accuracy =  46.875 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  74000  ,Loss =  1.9749697484785542  ,Accuracy =  53.125 %\n",
      "Iteration  74100  ,Loss =  2.21401766117848  ,Accuracy =  50.0 %\n",
      "Iteration  74200  ,Loss =  1.8899076305976197  ,Accuracy =  59.375 %\n",
      "Iteration  74300  ,Loss =  1.7433767979390367  ,Accuracy =  75.0 %\n",
      "Iteration  74400  ,Loss =  1.9283797046664095  ,Accuracy =  59.375 %\n",
      "Iteration  74500  ,Loss =  2.013808545316735  ,Accuracy =  59.375 %\n",
      "Iteration  74600  ,Loss =  1.7333100827646404  ,Accuracy =  68.75 %\n",
      "Iteration  74700  ,Loss =  2.250147215104179  ,Accuracy =  31.25 %\n",
      "Iteration  74800  ,Loss =  2.0759731197287534  ,Accuracy =  50.0 %\n",
      "Iteration  74900  ,Loss =  2.2266637912500182  ,Accuracy =  43.75 %\n",
      "Iteration  75000  ,Loss =  2.001892925602575  ,Accuracy =  50.0 %\n",
      "Iteration  75100  ,Loss =  2.063083946235892  ,Accuracy =  53.125 %\n",
      "Iteration  75200  ,Loss =  1.82117453948903  ,Accuracy =  65.625 %\n",
      "Iteration  75300  ,Loss =  2.0549461814773142  ,Accuracy =  43.75 %\n",
      "Iteration  75400  ,Loss =  1.9425834687743762  ,Accuracy =  56.25 %\n",
      "Iteration  75500  ,Loss =  1.7770828321576029  ,Accuracy =  65.625 %\n",
      "Iteration  75600  ,Loss =  1.5919813941013752  ,Accuracy =  78.125 %\n",
      "Iteration  75700  ,Loss =  2.0069052129211196  ,Accuracy =  50.0 %\n",
      "Iteration  75800  ,Loss =  1.761970067305622  ,Accuracy =  68.75 %\n",
      "Iteration  75900  ,Loss =  1.9821821639074986  ,Accuracy =  65.625 %\n",
      "Iteration  76000  ,Loss =  1.8521961363078674  ,Accuracy =  65.625 %\n",
      "Iteration  76100  ,Loss =  1.9104881256363193  ,Accuracy =  53.125 %\n",
      "Iteration  76200  ,Loss =  1.9356250070229977  ,Accuracy =  53.125 %\n",
      "Iteration  76300  ,Loss =  2.079956458824059  ,Accuracy =  59.375 %\n",
      "Iteration  76400  ,Loss =  2.1373895543892787  ,Accuracy =  43.75 %\n",
      "Iteration  76500  ,Loss =  2.137555772647966  ,Accuracy =  56.25 %\n",
      "Iteration  76600  ,Loss =  1.9192779379889693  ,Accuracy =  65.625 %\n",
      "Iteration  76700  ,Loss =  2.0641765186499588  ,Accuracy =  53.125 %\n",
      "Iteration  76800  ,Loss =  2.022362209743944  ,Accuracy =  50.0 %\n",
      "Iteration  76900  ,Loss =  2.1430082666455696  ,Accuracy =  50.0 %\n",
      "Iteration  77000  ,Loss =  2.1456934586186756  ,Accuracy =  53.125 %\n",
      "Iteration  77100  ,Loss =  1.8873243322005397  ,Accuracy =  56.25 %\n",
      "Iteration  77200  ,Loss =  1.8145204658454426  ,Accuracy =  65.625 %\n",
      "Iteration  77300  ,Loss =  1.8138449348910153  ,Accuracy =  65.625 %\n",
      "Iteration  77400  ,Loss =  2.198668814725581  ,Accuracy =  50.0 %\n",
      "Iteration  77500  ,Loss =  1.838675083822645  ,Accuracy =  62.5 %\n",
      "Iteration  77600  ,Loss =  1.7727677427060136  ,Accuracy =  68.75 %\n",
      "Iteration  77700  ,Loss =  2.1786965747632325  ,Accuracy =  53.125 %\n",
      "Iteration  77800  ,Loss =  2.0066840059492925  ,Accuracy =  50.0 %\n",
      "Iteration  77900  ,Loss =  1.6079350206317862  ,Accuracy =  71.875 %\n",
      "Iteration  78000  ,Loss =  1.9462392503974115  ,Accuracy =  56.25 %\n",
      "Iteration  78100  ,Loss =  2.21196062356777  ,Accuracy =  43.75 %\n",
      "Iteration  78200  ,Loss =  2.1571894895130135  ,Accuracy =  46.875 %\n",
      "Iteration  78300  ,Loss =  2.132449989460178  ,Accuracy =  43.75 %\n",
      "Iteration  78400  ,Loss =  1.8335983056700007  ,Accuracy =  56.25 %\n",
      "Iteration  78500  ,Loss =  1.7786823160325032  ,Accuracy =  59.375 %\n",
      "Iteration  78600  ,Loss =  1.9714426129116984  ,Accuracy =  53.125 %\n",
      "Iteration  78700  ,Loss =  2.075404413336227  ,Accuracy =  46.875 %\n",
      "Iteration  78800  ,Loss =  1.747620248447437  ,Accuracy =  65.625 %\n",
      "Iteration  78900  ,Loss =  1.7952224370504606  ,Accuracy =  59.375 %\n",
      "Iteration  79000  ,Loss =  2.0180385531303866  ,Accuracy =  65.625 %\n",
      "Iteration  79100  ,Loss =  1.9465978016287355  ,Accuracy =  50.0 %\n",
      "Iteration  79200  ,Loss =  1.8565323380911694  ,Accuracy =  65.625 %\n",
      "Iteration  79300  ,Loss =  1.942556151028794  ,Accuracy =  53.125 %\n",
      "Iteration  79400  ,Loss =  2.046803570079037  ,Accuracy =  46.875 %\n",
      "Iteration  79500  ,Loss =  1.8542022560526426  ,Accuracy =  65.625 %\n",
      "Iteration  79600  ,Loss =  1.9617342591885318  ,Accuracy =  59.375 %\n",
      "Iteration  79700  ,Loss =  2.0197645713883006  ,Accuracy =  53.125 %\n",
      "Iteration  79800  ,Loss =  2.0351765275342135  ,Accuracy =  56.25 %\n",
      "Iteration  79900  ,Loss =  2.187455725924252  ,Accuracy =  40.625 %\n",
      "Iteration  80000  ,Loss =  1.8063500189212949  ,Accuracy =  62.5 %\n",
      "Iteration  80100  ,Loss =  2.0728299203976617  ,Accuracy =  53.125 %\n",
      "Iteration  80200  ,Loss =  1.8418681080526016  ,Accuracy =  56.25 %\n",
      "Iteration  80300  ,Loss =  1.8764269115956194  ,Accuracy =  56.25 %\n",
      "Iteration  80400  ,Loss =  1.744424875147348  ,Accuracy =  56.25 %\n",
      "Iteration  80500  ,Loss =  1.8028293172617027  ,Accuracy =  59.375 %\n",
      "Iteration  80600  ,Loss =  2.1234056961998213  ,Accuracy =  53.125 %\n",
      "Iteration  80700  ,Loss =  1.996567281518479  ,Accuracy =  62.5 %\n",
      "Iteration  80800  ,Loss =  2.055335018674653  ,Accuracy =  43.75 %\n",
      "Iteration  80900  ,Loss =  1.8804950018198592  ,Accuracy =  53.125 %\n",
      "Iteration  81000  ,Loss =  1.8961777140945828  ,Accuracy =  53.125 %\n",
      "Iteration  81100  ,Loss =  1.9877072130208453  ,Accuracy =  59.375 %\n",
      "Iteration  81200  ,Loss =  2.0043869473664713  ,Accuracy =  50.0 %\n",
      "Iteration  81300  ,Loss =  1.862107994179173  ,Accuracy =  50.0 %\n",
      "Iteration  81400  ,Loss =  1.9360258863859592  ,Accuracy =  50.0 %\n",
      "Iteration  81500  ,Loss =  1.9316558341585166  ,Accuracy =  56.25 %\n",
      "Iteration  81600  ,Loss =  1.8981893607147313  ,Accuracy =  65.625 %\n",
      "Iteration  81700  ,Loss =  2.03187559566641  ,Accuracy =  50.0 %\n",
      "Iteration  81800  ,Loss =  1.939430292721633  ,Accuracy =  59.375 %\n",
      "Iteration  81900  ,Loss =  2.000465062918913  ,Accuracy =  46.875 %\n",
      "Iteration  82000  ,Loss =  2.2272078664579493  ,Accuracy =  53.125 %\n",
      "Iteration  82100  ,Loss =  2.104950580492114  ,Accuracy =  46.875 %\n",
      "Iteration  82200  ,Loss =  1.7941337935607868  ,Accuracy =  56.25 %\n",
      "Iteration  82300  ,Loss =  2.0735111261793637  ,Accuracy =  59.375 %\n",
      "Iteration  82400  ,Loss =  1.7960525342496858  ,Accuracy =  59.375 %\n",
      "Iteration  82500  ,Loss =  1.9870471367079916  ,Accuracy =  53.125 %\n",
      "Iteration  82600  ,Loss =  2.1365155135117564  ,Accuracy =  53.125 %\n",
      "Iteration  82700  ,Loss =  1.9808577736171142  ,Accuracy =  53.125 %\n",
      "Iteration  82800  ,Loss =  1.9682323718953272  ,Accuracy =  56.25 %\n",
      "Iteration  82900  ,Loss =  1.784345894386245  ,Accuracy =  62.5 %\n",
      "Iteration  83000  ,Loss =  2.0886245427068464  ,Accuracy =  50.0 %\n",
      "Iteration  83100  ,Loss =  1.8938045369846406  ,Accuracy =  65.625 %\n",
      "Iteration  83200  ,Loss =  1.9634407938327485  ,Accuracy =  53.125 %\n",
      "Iteration  83300  ,Loss =  1.885610764692974  ,Accuracy =  53.125 %\n",
      "Iteration  83400  ,Loss =  2.112644611955931  ,Accuracy =  50.0 %\n",
      "Iteration  83500  ,Loss =  2.0193763525887487  ,Accuracy =  43.75 %\n",
      "Iteration  83600  ,Loss =  2.109388462717981  ,Accuracy =  50.0 %\n",
      "Iteration  83700  ,Loss =  2.043373276772612  ,Accuracy =  46.875 %\n",
      "Iteration  83800  ,Loss =  1.8658102959481395  ,Accuracy =  50.0 %\n",
      "Iteration  83900  ,Loss =  1.6459339682591816  ,Accuracy =  62.5 %\n",
      "Iteration  84000  ,Loss =  2.210189739225947  ,Accuracy =  37.5 %\n",
      "Iteration  84100  ,Loss =  1.8443395580501802  ,Accuracy =  62.5 %\n",
      "Iteration  84200  ,Loss =  1.883017409873173  ,Accuracy =  56.25 %\n",
      "Iteration  84300  ,Loss =  1.9902871134991056  ,Accuracy =  43.75 %\n",
      "Iteration  84400  ,Loss =  1.709686753354441  ,Accuracy =  65.625 %\n",
      "Iteration  84500  ,Loss =  2.132708673680619  ,Accuracy =  46.875 %\n",
      "Iteration  84600  ,Loss =  2.5053809850192756  ,Accuracy =  34.375 %\n",
      "Iteration  84700  ,Loss =  1.8590860190662735  ,Accuracy =  53.125 %\n",
      "Iteration  84800  ,Loss =  1.994762788655219  ,Accuracy =  65.625 %\n",
      "Iteration  84900  ,Loss =  2.0156448748071263  ,Accuracy =  46.875 %\n",
      "Iteration  85000  ,Loss =  2.0668133199963368  ,Accuracy =  53.125 %\n",
      "Iteration  85100  ,Loss =  1.966072122466042  ,Accuracy =  56.25 %\n",
      "Iteration  85200  ,Loss =  1.7378333734204081  ,Accuracy =  68.75 %\n",
      "Iteration  85300  ,Loss =  1.973435178249368  ,Accuracy =  50.0 %\n",
      "Iteration  85400  ,Loss =  1.9021719302049847  ,Accuracy =  53.125 %\n",
      "Iteration  85500  ,Loss =  1.8363410388148258  ,Accuracy =  62.5 %\n",
      "Iteration  85600  ,Loss =  1.9433717738664495  ,Accuracy =  46.875 %\n",
      "Iteration  85700  ,Loss =  1.6397766096347854  ,Accuracy =  71.875 %\n",
      "Iteration  85800  ,Loss =  1.991403042795805  ,Accuracy =  62.5 %\n",
      "Iteration  85900  ,Loss =  1.7547603936104341  ,Accuracy =  68.75 %\n",
      "Iteration  86000  ,Loss =  1.9586124218673167  ,Accuracy =  53.125 %\n",
      "Iteration  86100  ,Loss =  1.8984185398914935  ,Accuracy =  53.125 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  86200  ,Loss =  2.297231832210828  ,Accuracy =  43.75 %\n",
      "Iteration  86300  ,Loss =  1.6306996635434374  ,Accuracy =  59.375 %\n",
      "Iteration  86400  ,Loss =  1.8400779458366472  ,Accuracy =  62.5 %\n",
      "Iteration  86500  ,Loss =  2.078708364205564  ,Accuracy =  37.5 %\n",
      "Iteration  86600  ,Loss =  1.9889037534586604  ,Accuracy =  59.375 %\n",
      "Iteration  86700  ,Loss =  1.9150743070690912  ,Accuracy =  56.25 %\n",
      "Iteration  86800  ,Loss =  1.7458069282923088  ,Accuracy =  59.375 %\n",
      "Iteration  86900  ,Loss =  1.8136463329493606  ,Accuracy =  59.375 %\n",
      "Iteration  87000  ,Loss =  1.7318106172782242  ,Accuracy =  68.75 %\n",
      "Iteration  87100  ,Loss =  2.0714379549960737  ,Accuracy =  56.25 %\n",
      "Iteration  87200  ,Loss =  1.7799463657878598  ,Accuracy =  65.625 %\n",
      "Iteration  87300  ,Loss =  1.9242676286313407  ,Accuracy =  43.75 %\n",
      "Iteration  87400  ,Loss =  1.9870398695507527  ,Accuracy =  56.25 %\n",
      "Iteration  87500  ,Loss =  1.8088913708699834  ,Accuracy =  62.5 %\n",
      "Iteration  87600  ,Loss =  1.7394822770074803  ,Accuracy =  65.625 %\n",
      "Iteration  87700  ,Loss =  2.185133864640476  ,Accuracy =  43.75 %\n",
      "Iteration  87800  ,Loss =  1.8977919518446245  ,Accuracy =  56.25 %\n",
      "Iteration  87900  ,Loss =  2.0246044155209795  ,Accuracy =  40.625 %\n",
      "Iteration  88000  ,Loss =  1.742961849882795  ,Accuracy =  62.5 %\n",
      "Iteration  88100  ,Loss =  1.9290210737316418  ,Accuracy =  56.25 %\n",
      "Iteration  88200  ,Loss =  2.304762059017139  ,Accuracy =  37.5 %\n",
      "Iteration  88300  ,Loss =  2.101227261937125  ,Accuracy =  46.875 %\n",
      "Iteration  88400  ,Loss =  1.9200687527975222  ,Accuracy =  59.375 %\n",
      "Iteration  88500  ,Loss =  1.882808704266652  ,Accuracy =  46.875 %\n",
      "Iteration  88600  ,Loss =  1.8316328178671648  ,Accuracy =  53.125 %\n",
      "Iteration  88700  ,Loss =  2.1909589997130463  ,Accuracy =  46.875 %\n",
      "Iteration  88800  ,Loss =  2.0630074858970056  ,Accuracy =  59.375 %\n",
      "Iteration  88900  ,Loss =  1.7830775939161851  ,Accuracy =  56.25 %\n",
      "Iteration  89000  ,Loss =  1.99076822295735  ,Accuracy =  65.625 %\n",
      "Iteration  89100  ,Loss =  2.1285553383623164  ,Accuracy =  46.875 %\n",
      "Iteration  89200  ,Loss =  1.9017178330980058  ,Accuracy =  59.375 %\n",
      "Iteration  89300  ,Loss =  2.2144861237717084  ,Accuracy =  46.875 %\n",
      "Iteration  89400  ,Loss =  1.865779533187844  ,Accuracy =  56.25 %\n",
      "Iteration  89500  ,Loss =  1.87603967987619  ,Accuracy =  46.875 %\n",
      "Iteration  89600  ,Loss =  1.8492316247964242  ,Accuracy =  65.625 %\n",
      "Iteration  89700  ,Loss =  1.6867956762436582  ,Accuracy =  75.0 %\n",
      "Iteration  89800  ,Loss =  1.745168749325438  ,Accuracy =  65.625 %\n",
      "Iteration  89900  ,Loss =  1.973869717599856  ,Accuracy =  50.0 %\n",
      "Iteration  90000  ,Loss =  1.572888279643051  ,Accuracy =  68.75 %\n",
      "Iteration  90100  ,Loss =  2.0558775892334706  ,Accuracy =  53.125 %\n",
      "Iteration  90200  ,Loss =  1.892521580722402  ,Accuracy =  59.375 %\n",
      "Iteration  90300  ,Loss =  1.9026495545736208  ,Accuracy =  53.125 %\n",
      "Iteration  90400  ,Loss =  1.9792356548380061  ,Accuracy =  53.125 %\n",
      "Iteration  90500  ,Loss =  2.0148998403275047  ,Accuracy =  53.125 %\n",
      "Iteration  90600  ,Loss =  1.6978242503800332  ,Accuracy =  65.625 %\n",
      "Iteration  90700  ,Loss =  1.9190434571190225  ,Accuracy =  53.125 %\n",
      "Iteration  90800  ,Loss =  2.0311663815217904  ,Accuracy =  46.875 %\n",
      "Iteration  90900  ,Loss =  1.9116137952549503  ,Accuracy =  59.375 %\n",
      "Iteration  91000  ,Loss =  2.3345101639516743  ,Accuracy =  31.25 %\n",
      "Iteration  91100  ,Loss =  1.9493232027833716  ,Accuracy =  56.25 %\n",
      "Iteration  91200  ,Loss =  1.6974140424610038  ,Accuracy =  68.75 %\n",
      "Iteration  91300  ,Loss =  2.0816496017440542  ,Accuracy =  59.375 %\n",
      "Iteration  91400  ,Loss =  1.4488325809859524  ,Accuracy =  78.125 %\n",
      "Iteration  91500  ,Loss =  1.6938648380403931  ,Accuracy =  53.125 %\n",
      "Iteration  91600  ,Loss =  2.145761048732153  ,Accuracy =  43.75 %\n",
      "Iteration  91700  ,Loss =  1.7851197242710106  ,Accuracy =  59.375 %\n",
      "Iteration  91800  ,Loss =  1.9338484162015552  ,Accuracy =  50.0 %\n",
      "Iteration  91900  ,Loss =  1.9725757538863704  ,Accuracy =  62.5 %\n",
      "Iteration  92000  ,Loss =  1.955932092086058  ,Accuracy =  56.25 %\n",
      "Iteration  92100  ,Loss =  1.7855176979873997  ,Accuracy =  62.5 %\n",
      "Iteration  92200  ,Loss =  1.5540060330113912  ,Accuracy =  71.875 %\n",
      "Iteration  92300  ,Loss =  1.9717427898743805  ,Accuracy =  40.625 %\n",
      "Iteration  92400  ,Loss =  1.788915392913724  ,Accuracy =  56.25 %\n",
      "Iteration  92500  ,Loss =  2.34222007382981  ,Accuracy =  53.125 %\n",
      "Iteration  92600  ,Loss =  1.7083123499146573  ,Accuracy =  65.625 %\n",
      "Iteration  92700  ,Loss =  1.939850379456084  ,Accuracy =  56.25 %\n",
      "Iteration  92800  ,Loss =  1.865081977498588  ,Accuracy =  56.25 %\n",
      "Iteration  92900  ,Loss =  1.8794862254013125  ,Accuracy =  56.25 %\n",
      "Iteration  93000  ,Loss =  1.8502866265049405  ,Accuracy =  53.125 %\n",
      "Iteration  93100  ,Loss =  1.8814074225284334  ,Accuracy =  59.375 %\n",
      "Iteration  93200  ,Loss =  2.0158911676042948  ,Accuracy =  50.0 %\n",
      "Iteration  93300  ,Loss =  1.8116321513661569  ,Accuracy =  56.25 %\n",
      "Iteration  93400  ,Loss =  1.8483957521936543  ,Accuracy =  53.125 %\n",
      "Iteration  93500  ,Loss =  1.7041159745290173  ,Accuracy =  62.5 %\n",
      "Iteration  93600  ,Loss =  1.7613160539154569  ,Accuracy =  68.75 %\n",
      "Iteration  93700  ,Loss =  1.8575676968318613  ,Accuracy =  59.375 %\n",
      "Iteration  93800  ,Loss =  1.8336099566657855  ,Accuracy =  53.125 %\n",
      "Iteration  93900  ,Loss =  1.7790296536645878  ,Accuracy =  65.625 %\n",
      "Iteration  94000  ,Loss =  1.6650027923106394  ,Accuracy =  56.25 %\n",
      "Iteration  94100  ,Loss =  1.966489720970448  ,Accuracy =  56.25 %\n",
      "Iteration  94200  ,Loss =  1.9812305293390537  ,Accuracy =  53.125 %\n",
      "Iteration  94300  ,Loss =  1.8801531449174371  ,Accuracy =  62.5 %\n",
      "Iteration  94400  ,Loss =  1.8208535938701456  ,Accuracy =  50.0 %\n",
      "Iteration  94500  ,Loss =  2.07899054512687  ,Accuracy =  59.375 %\n",
      "Iteration  94600  ,Loss =  1.7637386919093507  ,Accuracy =  56.25 %\n",
      "Iteration  94700  ,Loss =  2.0138867132087936  ,Accuracy =  65.625 %\n",
      "Iteration  94800  ,Loss =  1.5345066358448332  ,Accuracy =  78.125 %\n",
      "Iteration  94900  ,Loss =  1.989591642664859  ,Accuracy =  46.875 %\n",
      "Iteration  95000  ,Loss =  2.0625567581317443  ,Accuracy =  56.25 %\n",
      "Iteration  95100  ,Loss =  1.8563319403987064  ,Accuracy =  53.125 %\n",
      "Iteration  95200  ,Loss =  1.605598259367546  ,Accuracy =  68.75 %\n",
      "Iteration  95300  ,Loss =  2.0147044703310564  ,Accuracy =  59.375 %\n",
      "Iteration  95400  ,Loss =  1.7966052903437428  ,Accuracy =  56.25 %\n",
      "Iteration  95500  ,Loss =  1.674647324788916  ,Accuracy =  62.5 %\n",
      "Iteration  95600  ,Loss =  1.9832060696150853  ,Accuracy =  59.375 %\n",
      "Iteration  95700  ,Loss =  2.0384439643058334  ,Accuracy =  68.75 %\n",
      "Iteration  95800  ,Loss =  1.6664208652238084  ,Accuracy =  59.375 %\n",
      "Iteration  95900  ,Loss =  1.8452802814316667  ,Accuracy =  56.25 %\n",
      "Iteration  96000  ,Loss =  1.94822339870709  ,Accuracy =  56.25 %\n",
      "Iteration  96100  ,Loss =  1.6444844150657425  ,Accuracy =  65.625 %\n",
      "Iteration  96200  ,Loss =  1.847706821193293  ,Accuracy =  62.5 %\n",
      "Iteration  96300  ,Loss =  2.1938874989437807  ,Accuracy =  46.875 %\n",
      "Iteration  96400  ,Loss =  2.313419783029315  ,Accuracy =  40.625 %\n",
      "Iteration  96500  ,Loss =  1.7648123030294574  ,Accuracy =  50.0 %\n",
      "Iteration  96600  ,Loss =  1.7572953886018863  ,Accuracy =  53.125 %\n",
      "Iteration  96700  ,Loss =  1.7588898833419981  ,Accuracy =  65.625 %\n",
      "Iteration  96800  ,Loss =  1.9804952287712188  ,Accuracy =  56.25 %\n",
      "Iteration  96900  ,Loss =  1.891262031568218  ,Accuracy =  59.375 %\n",
      "Iteration  97000  ,Loss =  2.0941584114722387  ,Accuracy =  56.25 %\n",
      "Iteration  97100  ,Loss =  1.975216544105324  ,Accuracy =  56.25 %\n",
      "Iteration  97200  ,Loss =  1.7794767403969467  ,Accuracy =  56.25 %\n",
      "Iteration  97300  ,Loss =  1.7301710238895383  ,Accuracy =  62.5 %\n",
      "Iteration  97400  ,Loss =  1.5517971830235502  ,Accuracy =  68.75 %\n",
      "Iteration  97500  ,Loss =  1.8938222807445702  ,Accuracy =  59.375 %\n",
      "Iteration  97600  ,Loss =  1.8529795666279145  ,Accuracy =  53.125 %\n",
      "Iteration  97700  ,Loss =  2.20407749291658  ,Accuracy =  37.5 %\n",
      "Iteration  97800  ,Loss =  1.7559548112507337  ,Accuracy =  59.375 %\n",
      "Iteration  97900  ,Loss =  2.009237163772397  ,Accuracy =  37.5 %\n",
      "Iteration  98000  ,Loss =  1.8706938786472205  ,Accuracy =  59.375 %\n",
      "Iteration  98100  ,Loss =  1.6741783208120746  ,Accuracy =  65.625 %\n",
      "Iteration  98200  ,Loss =  1.538495745115873  ,Accuracy =  68.75 %\n",
      "Iteration  98300  ,Loss =  1.9281918199397203  ,Accuracy =  53.125 %\n",
      "Iteration  98400  ,Loss =  1.9379559671768534  ,Accuracy =  59.375 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  98500  ,Loss =  1.7153788142907715  ,Accuracy =  68.75 %\n",
      "Iteration  98600  ,Loss =  1.9260813885982764  ,Accuracy =  56.25 %\n",
      "Iteration  98700  ,Loss =  1.8466662704604655  ,Accuracy =  65.625 %\n",
      "Iteration  98800  ,Loss =  1.8144465181054241  ,Accuracy =  53.125 %\n",
      "Iteration  98900  ,Loss =  1.6510289857585863  ,Accuracy =  62.5 %\n",
      "Iteration  99000  ,Loss =  2.064759182702223  ,Accuracy =  56.25 %\n",
      "Iteration  99100  ,Loss =  1.9549442777836665  ,Accuracy =  50.0 %\n",
      "Iteration  99200  ,Loss =  1.7695924349868142  ,Accuracy =  56.25 %\n",
      "Iteration  99300  ,Loss =  1.8036197109494991  ,Accuracy =  50.0 %\n",
      "Iteration  99400  ,Loss =  2.011529458809699  ,Accuracy =  43.75 %\n",
      "Iteration  99500  ,Loss =  1.7077200031354658  ,Accuracy =  59.375 %\n",
      "Iteration  99600  ,Loss =  1.8921379085019279  ,Accuracy =  53.125 %\n",
      "Iteration  99700  ,Loss =  1.7976874317740785  ,Accuracy =  56.25 %\n",
      "Iteration  99800  ,Loss =  1.7143867033583624  ,Accuracy =  62.5 %\n",
      "Iteration  99900  ,Loss =  1.8483364818903831  ,Accuracy =  59.375 %\n"
     ]
    }
   ],
   "source": [
    "X = inpX.copy()\n",
    "input_size = X.shape[1]\n",
    "network = NeuralNetwork(input_size,output_size,hidden_layers_sizes,activation)\n",
    "network.train(X,Y.astype(int),batch_size,n0,max_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.28644501278772\n"
     ]
    }
   ],
   "source": [
    "predictions = network.predict(X.copy())\n",
    "print(100 * np.sum(predictions == Y)/Y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "testX = load_data(testing_data_path,avg,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = network.predict(testX)\n",
    "np.savetxt(output_path,predictions,fmt=\"%i\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
